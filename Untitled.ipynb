{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters \n",
    "learning_rate=0.001\n",
    "training_steps=500\n",
    "batch_size=32\n",
    "display_step=20\n",
    "\n",
    "#network parameters \n",
    "num_input_units=80\n",
    "timesteps= 28*28\n",
    "num_classes=10\n",
    "num_hidden_units =200\n",
    "num_output_units =10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=tf.random_uniform(shape=[num_hidden_units,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_in=tf.where(tf.greater(tf.random_uniform(shape=[num_input_units,1]),1.0),\n",
    "                  tf.constant(1.0,shape=[num_input_units,1],dtype=tf.float32),\n",
    "                              tf.constant(0.0,shape=[num_input_units,1],dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=tf.constant(1.0,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    " [spike,state]=LIFLayer(num_hidden_units,num_input_units,dt,spike_in,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OutputLayer(k,j,spike_in,dt,state):\n",
    "    neurons=k\n",
    "    inputs=j\n",
    "    tau_m = 5.0\n",
    "    # tensor variables \n",
    "    V_out = tf.contrib.eager.Variable(tf.constant(0.0,shape=[k,1],dtype=tf.float32),name='V_out')\n",
    "    W_out = tf.contrib.eager.Variable(tf.random_normal(shape=[k,j],mean=0.0,stddev=0.1,dtype=tf.float32),name='W_out')\n",
    "    G_out= tf.contrib.eager.Variable(tf.ones(shape=[k,1],dtype=tf.float32),name='G_out')\n",
    "    \n",
    "    ## update membrane dynamics \n",
    "    dv_out=tf.divide(state,tau_m)\n",
    "    V_temp=tf.subtract(state,dv_out*dt)\n",
    "    V_update=tf.clip_by_value(V_temp,tf.constant(0.0,shape=[k,1]),tf.constant(100.0,shape=[k,1]))\n",
    "    spike_in_float=tf.cast(spike_in,tf.float32)\n",
    "    spike_temp=tf.transpose(tf.tile(spike_in_float,[1,k]))\n",
    "    weight_update=tf.multiply(W_out,spike_temp)\n",
    "    G_update=tf.reduce_sum(weight_update, 1, keepdims=True)\n",
    "    # not sure about this step\n",
    "    v_membrane = tf.add(V_update,G_update)\n",
    "    return v_membrane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_rec=tf.where(tf.greater(tf.random_uniform(shape=[num_hidden_units,1]),0.5),\n",
    "                  tf.constant(1.0,shape=[num_hidden_units,1],dtype=tf.float32),\n",
    "                              tf.constant(0.0,shape=[num_hidden_units,1],dtype=tf.float32))\n",
    "state_out=tf.random_uniform(shape=[num_output_units,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=38289, shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 1.3298843 ],\n",
       "       [-0.19542417],\n",
       "       [ 1.5076162 ],\n",
       "       [ 0.9977307 ],\n",
       "       [ 0.4538017 ],\n",
       "       [ 1.7332283 ],\n",
       "       [ 0.92777336],\n",
       "       [ 1.9465357 ],\n",
       "       [-0.4065798 ],\n",
       "       [-0.10051703]], dtype=float32)>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vout = OutputLayer(num_output_units,num_hidden_units,spike_rec,dt,state_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    t.watch(spike_rec)\n",
    "    Vout = OutputLayer(num_output_units,num_hidden_units,spike_rec,dt,state_out)\n",
    "\n",
    "dz_dx = t.gradient(Vout, spike_rec) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=45005, shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0. ],\n",
       "       [0. ],\n",
       "       [0.8],\n",
       "       [0. ],\n",
       "       [0.8],\n",
       "       [0.8],\n",
       "       [0.8],\n",
       "       [0.8],\n",
       "       [0.8],\n",
       "       [0.8]], dtype=float32)>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_rec=tf.where(tf.greater(tf.random_uniform(shape=[num_hidden_units,1]),0.5),\n",
    "                  tf.constant(1.0,shape=[num_hidden_units,1],dtype=tf.float32),\n",
    "                              tf.constant(0.0,shape=[num_hidden_units,1],dtype=tf.float32))\n",
    "x = tf.random_uniform(shape=[num_output_units,1])\n",
    "W_o = tf.contrib.eager.Variable(tf.random_normal(shape=[num_output_units,num_hidden_units],mean=0.0,stddev=0.1,dtype=tf.float32))\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "  t.watch(x)\n",
    "  y=tf.divide(x,5.0)\n",
    "  z=tf.subtract(x,y*dt)\n",
    "  z1=tf.clip_by_value(z,tf.constant(0.0,shape=[num_output_units,1]),tf.constant(0.5,shape=[num_output_units,1]))\n",
    "  z2=tf.cast(z1,tf.float64)\n",
    "  sp=tf.cast(spike_rec,tf.float32)\n",
    "  sp1=tf.transpose(tf.tile(sp,[1,num_output_units]))\n",
    "  w1=tf.multiply(W_o,sp1)\n",
    "  G_up=tf.reduce_sum(w1, 1, keepdims=True) \n",
    "  v_mem = tf.divide(z1,G_up)\n",
    "# Derivative of z with respect to the original input tensor x\n",
    "dz_dx = t.gradient(z2, x)\n",
    "dz_dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=tf.clip_by_value(tf.add(tf.random_uniform(shape=[num_hidden_units,1]),tf.constant(.5,shape=[num_hidden_units,1])),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[spike,state]=LIFLayer(num_hidden_units,num_input_units,dt,spike_in,state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=45174, shape=(200, 200), dtype=float32, numpy=\n",
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    t.watch(spike_rec)\n",
    "    v_update=tf.where(tf.cast(spike_rec,tf.bool),tf.constant(0.0,shape=[num_hidden_units,1],dtype=tf.float32),state)\n",
    "    v_update1=tf.subtract(state,tf.multiply(spike_rec,tf.constant(1.0,shape=[num_hidden_units,1],dtype=tf.float32)))\n",
    "    Spike_temp=tf.transpose(tf.tile(spike_rec,[1,num_hidden_units]))\n",
    "dz_dx = t.gradient(Spike_temp, spike_rec) \n",
    "#plt.figure()\n",
    "#plt.subplot(3,1,1)\n",
    "#plt.plot(v_update1.numpy())\n",
    "#plt.subplot(3,1,2)\n",
    "#plt.plot(v_update.numpy())\n",
    "#plt.subplot(3,1,3)\n",
    "#plt.plot(state.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIFLayer(n,m,dt,Spike_in,state):\n",
    "    neurons=n\n",
    "    inputs=m\n",
    "    tau_m = 5.0\n",
    "    v_theta = 1.0\n",
    "    v_reset = 0.0\n",
    "    tau_s = 5.0\n",
    "    tau_refract = 3.0\n",
    "    # tensor variables \n",
    "    V = tf.contrib.eager.Variable(tf.constant(0.0,shape=[n,1],dtype=tf.float32),name='V')\n",
    "    Spike = tf.contrib.eager.Variable(tf.constant(v_reset,shape=[n,1],dtype=tf.float32),name='Spike')\n",
    "    W_rec = tf.contrib.eager.Variable(tf.random_normal(shape=[n,n],mean=1.0,stddev=0.1,dtype=tf.float32),name='W_rec')\n",
    "    W_in = tf.contrib.eager.Variable(tf.random_normal(shape=[n,m],mean=1.0,stddev=0.1,dtype=tf.float32),name='W_in')\n",
    "    G=tf.contrib.eager.Variable(tf.ones(shape=[n,1],dtype=tf.float32),name='G')\n",
    "    S=tf.contrib.eager.Variable(tf.zeros(shape=[n,n],dtype=tf.float32),name='S')\n",
    "    G_in=tf.contrib.eager.Variable(tf.ones(shape=[n,1],dtype=tf.float32),name='G_in')\n",
    "    S_in=tf.contrib.eager.Variable(tf.zeros(shape=[n,m],dtype=tf.float32),name='S_in')\n",
    "    I_syn=tf.contrib.eager.Variable(tf.ones(shape=[n,1],dtype=tf.float32),name='I_syn')\n",
    "    t_reset=tf.contrib.eager.Variable(tf.ones(shape=[n,1],dtype=tf.float32),name='t_reset')\n",
    "    \n",
    "    # subfunctions \n",
    "    @tf.custom_gradient\n",
    "    def calculate_crossing_op(x):\n",
    "        x_norm=tf.divide(tf.subtract(x,tf.constant(v_theta,shape=[n,1])),\n",
    "                         tf.constant(v_theta,shape=[n,1]))\n",
    "        temp=tf.greater_equal(x,tf.constant(v_theta,shape=[n,1],dtype=tf.float32))\n",
    "        def grad(dy):            \n",
    "            return tf.maximum(tf.constant(0.0,dtype=tf.float32),tf.subtract(tf.constant(1.0,dtype=tf.float32),tf.abs(x_norm)))  \n",
    "        return tf.cast(temp,tf.float32), grad\n",
    "\n",
    "    ## spiking neuron dynamics \n",
    "    Spike=calculate_crossing_op(state)\n",
    "    v_update=tf.subtract(state,tf.multiply(tf.cast(Spike,tf.float32),tf.constant(v_theta,shape=[n,1],dtype=tf.float32)))\n",
    "    ## update conductance for recurrent spikes \n",
    "    dS_op=tf.divide(S,tau_s)\n",
    "    dS_in_op=tf.divide(S_in,tau_s)\n",
    "    S_temp=tf.subtract(S,dS_op*dt)\n",
    "    S_in_temp=tf.subtract(S_in,dS_in_op*dt)\n",
    "    S_op=tf.clip_by_value(S_temp,tf.constant(0.0,shape=[n,n]),tf.constant(100.0,shape=[n,n]))\n",
    "    S_in_op=tf.clip_by_value(S_in_temp,tf.constant(0.0,shape=[n,m]),tf.constant(100.0,shape=[n,m]))\n",
    "    Spike_op_float=tf.cast(Spike,tf.float32)\n",
    "    Spike_in_op_float=tf.cast(Spike_in,tf.float32)\n",
    "    Spike_ax=tf.clip_by_value(tf.subtract(tf.transpose(tf.tile(Spike_op_float,[1,n])),\n",
    "                                            tf.eye(n,dtype=tf.float32)),0.0,100.0)\n",
    "\n",
    "    Spike_in_temp=tf.transpose(tf.tile(Spike_in_op_float,[1,n]))\n",
    "    Spike_in_ax=Spike_in_temp\n",
    "    S_update= tf.add(S,Spike_ax)\n",
    "    S_in_update=tf.add(S_in,Spike_in_ax)\n",
    "    G_op=tf.reduce_sum(tf.multiply(W_rec,S_update), 1, keepdims=True)\n",
    "    G_in_op=tf.reduce_sum(tf.multiply(W_in,S_in_update), 1, keepdims=True)\n",
    "    I_input=tf.add(tf.multiply(G_op,v_update),tf.multiply(G_in_op,v_update))\n",
    "    ## update voltages\n",
    "    # find neurons in refractory \n",
    "    t_subtract= tf.subtract(t_reset,tf.constant(1.0,shape=[n,1]))\n",
    "    t_margin=tf.clip_by_value(t_subtract,0.0,100)\n",
    "    t_reset_update=tf.add(t_margin,tf.multiply(Spike,tf.constant(v_theta,shape=[n,1],dtype=tf.float32)))\n",
    "    eligilible_update=tf.cast(tf.equal(t_reset_update,tf.constant(0.0,shape=[n,1])),tf.float32)\n",
    "    # update voltage\n",
    "    dV_op=tf.add(tf.constant(v_reset,shape=[n,1],dtype=tf.float32),tf.multiply(eligilible_update,\n",
    "                                                                               tf.divide(tf.subtract(I_input,v_update),tau_m)))\n",
    "    V_out=tf.add(v_update,tf.multiply(dV_op,dt))\n",
    "    return Spike, v_update\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "[spike,state]=LIFLayer(num_hidden_units,num_input_units,dt,spike_in,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb3b6aa048>]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_gradient(x,n):\n",
    "    @tf.custom_gradient\n",
    "    def calculate_crossing_op(x):\n",
    "        x_norm=tf.divide(tf.subtract(x,tf.constant(1.0,shape=[n,1])),tf.constant(1.0,shape=[n,1]))\n",
    "        temp=tf.greater_equal(x,tf.constant(1.0,shape=[n,1],dtype=tf.float32))\n",
    "        def grad(dy):            \n",
    "            return tf.maximum(tf.constant(0.0,dtype=tf.float32),tf.subtract(tf.constant(1.0,dtype=tf.float32),tf.abs(x_norm)))  \n",
    "        return tf.cast(temp,tf.float32), grad\n",
    "    z = calculate_crossing_op(x)\n",
    "    return z \n",
    "\n",
    "x = tf.reshape(tf.linspace(-10.0, 10.0, 300, name=\"linspace\"),shape=[300,1])\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    z = test_gradient(x,300)\n",
    "\n",
    "dz_dx = t.gradient(z, x) \n",
    "plt.figure(figsize=[15,10])\n",
    "plt.plot(x.numpy().flatten(),z.numpy().flatten())\n",
    "plt.plot(x.numpy(),dz_dx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54372, shape=(200, 1), dtype=float32, numpy=\n",
       "array([[0.9991296 ],\n",
       "       [1.0956359 ],\n",
       "       [0.5631111 ],\n",
       "       [0.42639047],\n",
       "       [1.0805414 ],\n",
       "       [0.8627391 ],\n",
       "       [0.93013996],\n",
       "       [0.9239382 ],\n",
       "       [0.9757657 ],\n",
       "       [0.30683824],\n",
       "       [0.82989526],\n",
       "       [1.0814683 ],\n",
       "       [0.44900432],\n",
       "       [0.68188053],\n",
       "       [0.9220836 ],\n",
       "       [0.810352  ],\n",
       "       [0.85724384],\n",
       "       [0.6600555 ],\n",
       "       [0.8251503 ],\n",
       "       [0.7121858 ],\n",
       "       [0.79784405],\n",
       "       [0.76805365],\n",
       "       [0.58105165],\n",
       "       [0.761428  ],\n",
       "       [0.8077094 ],\n",
       "       [0.73038816],\n",
       "       [0.47590268],\n",
       "       [0.95611024],\n",
       "       [0.84234273],\n",
       "       [1.0228528 ],\n",
       "       [0.67334247],\n",
       "       [0.8296457 ],\n",
       "       [1.0167838 ],\n",
       "       [1.1792346 ],\n",
       "       [0.9692254 ],\n",
       "       [1.0297743 ],\n",
       "       [0.82117194],\n",
       "       [0.7158686 ],\n",
       "       [1.0492226 ],\n",
       "       [0.69498986],\n",
       "       [0.73797345],\n",
       "       [0.48742592],\n",
       "       [0.80969673],\n",
       "       [0.5059848 ],\n",
       "       [0.44907838],\n",
       "       [0.849554  ],\n",
       "       [0.7580471 ],\n",
       "       [0.62764573],\n",
       "       [0.6639627 ],\n",
       "       [0.75795174],\n",
       "       [0.5108366 ],\n",
       "       [0.92813134],\n",
       "       [0.53862655],\n",
       "       [0.671029  ],\n",
       "       [0.703277  ],\n",
       "       [0.79912585],\n",
       "       [1.1064717 ],\n",
       "       [0.7789922 ],\n",
       "       [0.7671862 ],\n",
       "       [0.8049782 ],\n",
       "       [0.45896626],\n",
       "       [0.76575625],\n",
       "       [0.94440514],\n",
       "       [0.56516826],\n",
       "       [0.7447226 ],\n",
       "       [0.98840743],\n",
       "       [0.60400915],\n",
       "       [0.8029286 ],\n",
       "       [0.89867103],\n",
       "       [0.7930645 ],\n",
       "       [0.82154185],\n",
       "       [0.72712994],\n",
       "       [0.5865855 ],\n",
       "       [0.79271364],\n",
       "       [0.8240211 ],\n",
       "       [0.7557812 ],\n",
       "       [0.9394067 ],\n",
       "       [0.7579302 ],\n",
       "       [0.9772553 ],\n",
       "       [0.5756696 ],\n",
       "       [0.6684757 ],\n",
       "       [0.7035379 ],\n",
       "       [0.74581426],\n",
       "       [0.9757129 ],\n",
       "       [0.8775558 ],\n",
       "       [0.6204851 ],\n",
       "       [0.61236435],\n",
       "       [0.8724276 ],\n",
       "       [1.0136906 ],\n",
       "       [0.53676915],\n",
       "       [0.61960113],\n",
       "       [0.7748715 ],\n",
       "       [0.7151594 ],\n",
       "       [0.9251341 ],\n",
       "       [0.8632001 ],\n",
       "       [0.5301236 ],\n",
       "       [0.5799099 ],\n",
       "       [0.6456358 ],\n",
       "       [0.7967302 ],\n",
       "       [0.6621619 ],\n",
       "       [1.0268669 ],\n",
       "       [0.69076276],\n",
       "       [1.1932242 ],\n",
       "       [0.8348615 ],\n",
       "       [1.2032366 ],\n",
       "       [1.4103565 ],\n",
       "       [1.1279469 ],\n",
       "       [1.8239222 ],\n",
       "       [1.7827668 ],\n",
       "       [1.7015148 ],\n",
       "       [1.9447231 ],\n",
       "       [1.8442211 ],\n",
       "       [1.7437181 ],\n",
       "       [1.6432161 ],\n",
       "       [1.5427132 ],\n",
       "       [1.4422112 ],\n",
       "       [1.3417082 ],\n",
       "       [1.2412062 ],\n",
       "       [1.1407032 ],\n",
       "       [1.0402012 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_gradient(x,Spike_in,n,m):\n",
    "    tau_m = 5.0\n",
    "    v_theta = 1.0\n",
    "    v_reset = 0.0\n",
    "    tau_s = 5.0\n",
    "    tau_refract = 3.0\n",
    "    S=tf.contrib.eager.Variable(tf.zeros(shape=[n,n],dtype=tf.float32),name='S')\n",
    "    S_in=tf.contrib.eager.Variable(tf.zeros(shape=[n,m],dtype=tf.float32),name='S_in')\n",
    "    W_rec = tf.contrib.eager.Variable(tf.random_normal(shape=[n,n],mean=0.0,stddev=0.1,dtype=tf.float32),name='W_rec')\n",
    "    W_in = tf.contrib.eager.Variable(tf.random_normal(shape=[n,m],mean=1.0,stddev=0.1,dtype=tf.float32),name='W_in')\n",
    "    t_reset=tf.contrib.eager.Variable(tf.ones(shape=[n,1],dtype=tf.float32),name='t_reset')\n",
    "    @tf.custom_gradient\n",
    "    def calculate_crossing_op(x):\n",
    "        x_norm=tf.divide(tf.subtract(x,tf.constant(1.0,shape=[n,1])),tf.constant(1.0,shape=[n,1]))\n",
    "        temp=tf.greater_equal(x,tf.constant(1.0,shape=[n,1],dtype=tf.float32))\n",
    "        def grad(dy):            \n",
    "            return tf.maximum(tf.constant(0.0,dtype=tf.float32),tf.subtract(tf.constant(1.0,dtype=tf.float32),tf.abs(x_norm)))  \n",
    "        return tf.cast(temp,tf.float32), grad\n",
    "    Spike=calculate_crossing_op(x)\n",
    "    v_update=tf.subtract(x,tf.multiply(tf.cast(Spike,tf.float32),tf.constant(1.0,shape=[n,1],dtype=tf.float32)))\n",
    "    ## update conductance for recurrent spikes \n",
    "    dS_op=tf.divide(S,3.0)\n",
    "    dS_in_op=tf.divide(S_in,tau_s)\n",
    "    S_temp=tf.subtract(S,dS_op*dt)\n",
    "    S_in_temp=tf.subtract(S_in,dS_in_op*dt)\n",
    "    S_op=tf.clip_by_value(S_temp,tf.constant(0.0,shape=[n,n]),tf.constant(100.0,shape=[n,n]))\n",
    "    S_in_op=tf.clip_by_value(S_in_temp,tf.constant(0.0,shape=[n,m]),tf.constant(100.0,shape=[n,m]))\n",
    "    Spike_op_float=tf.cast(Spike,tf.float32)\n",
    "    Spike_in_op_float=tf.cast(Spike_in,tf.float32)\n",
    "    Spike_ax=tf.clip_by_value(tf.subtract(tf.transpose(tf.tile(Spike_op_float,[1,n])),\n",
    "                                            tf.eye(n,dtype=tf.float32)),0.0,100.0)\n",
    "\n",
    "    Spike_in_temp=tf.transpose(tf.tile(Spike_in_op_float,[1,n]))\n",
    "    Spike_in_ax=Spike_in_temp\n",
    "    S_update= tf.add(S,Spike_ax)\n",
    "    S_in_update=tf.add(S_in,Spike_in_ax)\n",
    "    G_op=tf.reduce_sum(tf.multiply(W_rec,S_update), 1, keepdims=True)\n",
    "    G_in_op=tf.reduce_sum(tf.multiply(W_in,S_in_update), 1, keepdims=True)\n",
    "    I_input=tf.add(tf.multiply(G_op,v_update),tf.multiply(G_in_op,v_update))\n",
    "\n",
    "    ## update voltages\n",
    "    # find neurons in refractory \n",
    "    t_subtract= tf.subtract(t_reset,tf.constant(1.0,shape=[n,1]))\n",
    "    \n",
    "    t_margin=tf.clip_by_value(t_subtract,0.0,100)\n",
    "    t_reset_update=tf.add(t_margin,tf.multiply(Spike,tf.constant(v_theta,shape=[n,1],dtype=tf.float32)))\n",
    "\n",
    "    eligilible_update=tf.cast(tf.equal(t_reset_update,tf.constant(0.0,shape=[n,1])),tf.float32)\n",
    "#     # update voltage\n",
    "    dV_op=tf.add(tf.constant(v_reset,shape=[n,1],dtype=tf.float32),tf.multiply(eligilible_update,\n",
    "                                                                                tf.divide(tf.subtract(I_input,v_update),tau_m)))\n",
    "\n",
    "    V_out=tf.add(v_update,tf.multiply(dV_op,dt))\n",
    "    return V_out\n",
    "\n",
    "x = tf.reshape(tf.linspace(-10.0, 10.0, 200, name=\"linspace\"),shape=[200,1])\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    z = test_gradient(x,spike_in,200,num_input_units)\n",
    "\n",
    "dz_dx = t.gradient(z, x) \n",
    "#plt.figure(figsize=[15,10])\n",
    "#plt.plot(x.numpy().flatten(),z.numpy().flatten())\n",
    "#plt.plot(x.numpy(),dz_dx.numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_test=tf.get_variable('W_test',shape=[10,10],dtype=tf.float32,initializer=tf.random_normal_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calcualte_crossings(x,threshold,output_size):\n",
    "    \"\"\"input :x : a 2D tensor with batch x n \n",
    "    outputs a tensor with the same size as x \n",
    "    and values of 0 or 1 depending on comparison between \n",
    "    x and threshold\"\"\" \n",
    "    dtype=x.dtype\n",
    "    shape=x.get_shape()\n",
    "    total_x_size=shape[1].value\n",
    "    thresholds=tf.constant(threshold,shape=[total_x_size,output_size],dtype=dtype)\n",
    "    # if it has one row \n",
    "    res=tf.greater_equal(x,thresholds,dtype=tf.float32)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingRnnCell(tf.contrib.rnn.RNNCell):\n",
    "    # input and output of the network are spikes\n",
    "    # states of the network are membrane voltage and synaptic input S \n",
    "    def __init__(self,num_units,tau_m=5.0,v_theta=1.0,v_reset=0.0,tau_s=5.0,tau_refract=3.0,reuse=None):\n",
    "        super(SpikingRnnCell,self).__init__(_reuse=reuse)\n",
    "        self.num_units=num_units\n",
    "        self.tau_m=tau_m\n",
    "        self.v_theta=v_theta\n",
    "        self.v_reset=v_reset\n",
    "        self.tau_s=tau_s\n",
    "        self.tau_refract=tau_refract\n",
    "        self._weight_linear=None\n",
    "        \n",
    "        # variables \n",
    "        \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self.num_units\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return 1\n",
    "    \n",
    "        \n",
    "    #call routine is used by tensorflow to compute the output and next state of the network,\n",
    "    def __call__(self,inputs,state):\n",
    "        \n",
    "        #output is some funtion of states\n",
    "        # first slice up the state into three vectors, \n",
    "        v_mem=tf.slice(state,[0,0],[self.num_units,1])\n",
    "        g_mem=tf.slice(state,[self.num_units,0],[self.num_units,1])\n",
    "        t_mem=tf.slice(state,[2*self.num_units,0],[self.num_units,1])\n",
    "        #\n",
    "        spike=tf.cast(tf.greater_equal(v_mem,tf.constant(self.v_theta,shape=[self.state_size,1],dtype=tf.float32)),tf.float32)\n",
    "        v_update=tf.subtract(v_mem,tf.multiply(tf.cast(spike,tf.float32),\n",
    "                                               tf.constant(self.v_theta,shape=[self.num_units,1],dtype=tf.float32)))\n",
    "        #\n",
    "        #spike_rec=tf.clip_by_value(tf.subtract(tf.transpose(tf.tile(spike,[1,self.num_units])),\n",
    "        #                                    tf.eye(self.num_units,dtype=tf.float32)),0.0,100.0)\n",
    "        #spike_in=tf.transpose(tf.tile(tf.cast(inputs,tf.float32),[1,self.num_units]))\n",
    "        if self._weight_linear is None:\n",
    "            self._weight_linear=_Linear([inputs,spike],self.num_units,False)\n",
    "            \n",
    "        g_update=self._weight_linear([spike,inputs])\n",
    "        \n",
    "        \n",
    "        #g_update=tf.add(tf.reduce_sum(tf.multiply(self.W_rec,spike_rec), 1, keepdims=True),\n",
    "        #                tf.reduce_sum(tf.multiply(self.W_in,spike_in), 1, keepdims=True))\n",
    "        #\n",
    "        dg_mem=tf.subtract(g_mem,tf.divide(g_mem,self.tau_s))\n",
    "        #g_mem_new=tf.add(g_update,tf.subtract(g_mem,dg_mem))\n",
    "        g_mem_new=g_update\n",
    "        \n",
    "        #\n",
    "        if  np.not_equal(g_update.get_shape()[0],self.state_size) :\n",
    "            raise NotImplementedError(\"Abstract method\")\n",
    "        \n",
    "        I_input=tf.multiply(tf.transpose(g_update),v_update)\n",
    "        #                \n",
    "        t_subtract=tf.subtract(t_mem,tf.constant(1.0,shape=[self.num_units,1]))\n",
    "        t_margin=tf.clip_by_value(t_subtract,0.0,100.0)\n",
    "        t_mem_new=tf.add(t_margin,tf.multiply(spike,tf.constant(self.tau_refract,shape=[self.num_units,1],dtype=tf.float32)))\n",
    "        update_trace=tf.cast(tf.equal(t_mem_new,tf.constant(0.0,shape=[self.num_units,1])),tf.float32)\n",
    "        #\n",
    "        dv_mem=tf.add(tf.constant(self.v_reset,shape=[self.num_units,1],dtype=tf.float32),\n",
    "                      tf.multiply(update_trace,tf.divide(tf.subtract(I_input,v_update),self.tau_m)))\n",
    "        v_mem_new=tf.add(v_update,dv_mem)\n",
    "\n",
    "        return spike, tf.concat([v_mem_new,g_mem_new,t_mem_new],0)\n",
    "    \n",
    "    ## crossing fucntion \n",
    "    \n",
    "    #def calculate_crossing_op(self,x):\n",
    "    #    x_norm=tf.divide(tf.subtract(x,tf.constant(self.v_theta,shape=[self.state_size,1])),\n",
    "    #                     tf.constant(self.v_theta,shape=[self.state_size,1]))\n",
    "    #    temp=tf.greater_equal(x,tf.constant(self.v_theta,shape=[self.state_size,1],dtype=tf.float32))\n",
    "    #    def grad(dy):            \n",
    "    #        return tf.maximum(tf.constant(0.0,dtype=tf.float32),tf.subtract(tf.constant(1.0,dtype=tf.float32),tf.abs(x_norm)))  \n",
    "    #    return temp, grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calcualte_crossings(x,threshold):\n",
    "    \"\"\"input :x : a 2D tensor with batch x n \n",
    "    outputs a tensor with the same size as x \n",
    "    and values of 0 or 1 depending on comparison between \n",
    "    x and threshold\"\"\" \n",
    "    @tf.custom_gradient\n",
    "    def crossings(x):\n",
    "        dtype=x.dtype\n",
    "        shape=x.get_shape()\n",
    "        thresholds=tf.constant(threshold,shape=[shape[0].value,shape[1].value],dtype=dtype)\n",
    "        # if it has one row \n",
    "        res=tf.greater_equal(x,thresholds)\n",
    "        def grad(dy):\n",
    "            # calculate 1-|x|\n",
    "            temp=1-tf.abs(x)\n",
    "            dyres=tf.maximum(temp,0.0)\n",
    "            return dyres\n",
    "        return tf.cast(res,dtype=dtype), grad\n",
    "    z=crossings(x)\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.random_normal(mean=1,stddev=.5,shape=[1,100])\n",
    "x = tf.reshape(tf.linspace(-10.0, 10.0, 300, name=\"linspace\"),shape=[1,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = _calcualte_crossings(x,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54622, shape=(1, 300), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.]], dtype=float32)>"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.scalar_mul(5.0,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tensor_linear(x,y,output_size,w_type):\n",
    "    \"\"\"input - x : a 3D tensor with batch x n x m \n",
    "    w_type is a string indicating with weight is being process : W_in or W_rec\n",
    "    y is a 2D with size batch x m\n",
    "    \n",
    "    outputs a tensor  with size batch x n\n",
    "    \"\"\" \n",
    "    shape_x=x.get_shape()\n",
    "    shape_y=x.get_shape()\n",
    "    # \n",
    "    if tf.strings.regex_full_match(w_type,_INPUT_WEIGHT_NAME):\n",
    "        weight=tf.get_variable(_INPUT_WEIGHT_NAME,[shape_x[0],shape_x[1],shape_y[1]]) # [ n x m]\n",
    "    elif tf.strings.regex_full_match(w_type,_WEIGHT_WEIGHT_NAME):\n",
    "        weight=tf.get_variable(_RECURRENT_WEIGHT_NAME,[shape_x[0],shape_x[1],shape_x[1]]) # [n x n]\n",
    "    else:\n",
    "        raise ValueError(\"expecting W_rec or W_in as weight input\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=2 \n",
    "n=3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54657, shape=(2, 3, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12],\n",
       "        [13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(np.arange(1, 19, dtype=np.int32),\n",
    "                shape=[2, 3, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=tf.constant(2.0,shape=[n,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[1] is not a matrix [Op:MatMul] name: MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-590-b4c30013b1fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/KeRNL/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2018\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KeRNL/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4480\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4481\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4482\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KeRNL/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: In[1] is not a matrix [Op:MatMul] name: MatMul/"
     ]
    }
   ],
   "source": [
    "tf.matmul(weight,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54694, shape=(6, 3), dtype=int32, numpy=\n",
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12],\n",
       "       [13, 14, 15],\n",
       "       [16, 17, 18]], dtype=int32)>"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=tf.reshape(a,[-1,3])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54657, shape=(2, 3, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12],\n",
       "        [13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54657, shape=(2, 3, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12],\n",
       "        [13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.constant([[1,0,1],[0,1,0],[1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54713, shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=tf.matmul(b,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54704, shape=(6, 3), dtype=int32, numpy=\n",
       "array([[ 4,  5,  4],\n",
       "       [10, 11, 10],\n",
       "       [16, 17, 16],\n",
       "       [22, 23, 22],\n",
       "       [28, 29, 28],\n",
       "       [34, 35, 34]], dtype=int32)>"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=tf.reshape(h,[-1,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=54716, shape=(2, 3, 3), dtype=int32, numpy=\n",
       "array([[[ 4,  5,  1],\n",
       "        [10, 11,  4],\n",
       "        [16, 17,  7]],\n",
       "\n",
       "       [[22, 23, 10],\n",
       "        [28, 29, 13],\n",
       "        [34, 35, 16]]], dtype=int32)>"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(KeRNL)",
   "language": "python",
   "name": "kernl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
