{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf \n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# uplading mnist data \n",
    "\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/eghbal/MyData/KeRNL/logs/ffn/kernl_mnist_eta_weight_1e-03_batch_2e+01_hum_hidd_1e+03_steps_5e+01_run_20190304_0953'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the Model Parameters\n",
    "INPUT_SIZE=784\n",
    "HIDDEN_SIZE=1000\n",
    "OUTPUT_SIZE = 10  \n",
    "START_LEARNING_RATE=1e-3\n",
    "BATCH_SIZE=25\n",
    "NUM_TRAINING_STEPS = 50\n",
    "EPOCHS=200\n",
    "TEST_LENGTH=125\n",
    "DISPLAY_STEP=25\n",
    "weight_learning_rate=1e-3\n",
    "\n",
    "log_dir = os.environ['HOME']+\"/MyData/KeRNL/logs/ffn/kernl_mnist_eta_weight_%1.0e_batch_%1.0e_hum_hidd_%1.0e_steps_%1.0e_run_%s\" %(weight_learning_rate,BATCH_SIZE,HIDDEN_SIZE,NUM_TRAINING_STEPS, datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drelu(x):\n",
    "    return 1 - tf.maximum(0.0, tf.sign(-x))\n",
    "\n",
    "\n",
    "def dtanh(x):\n",
    "    return(1-tf.mul(tf.nn.tanh(x),tf.nn.tanh(x)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # define weights and inputs to the network\n",
    "    X = tf.placeholder('float', shape=[None, INPUT_SIZE])  \n",
    "    Y = tf.placeholder('float', shape=[None, OUTPUT_SIZE])\n",
    "    initializer = tf.random_normal_initializer(stddev=0.1)\n",
    "    # define a function for extraction of variable names\n",
    "     # Hidden Layer Variables\n",
    "    W_1 = tf.get_variable(\"Hidden_W\", shape=[INPUT_SIZE, HIDDEN_SIZE], initializer=initializer)\n",
    "    b_1 = tf.get_variable(\"Hidden_b\", shape=[HIDDEN_SIZE], initializer=initializer)\n",
    "  # output layer variables \n",
    "    W_2 = tf.get_variable(\"Output_W\", shape=[HIDDEN_SIZE, OUTPUT_SIZE], initializer=initializer)\n",
    "    b_2 = tf.get_variable(\"Output_b\", shape=[OUTPUT_SIZE], initializer=initializer)\n",
    "    # return weight \n",
    "    B=tf.get_variable('B',shape=[OUTPUT_SIZE,HIDDEN_SIZE],initializer=tf.initializers.random_uniform(minval=-0.5,maxval=0.5))\n",
    "    trainables=[W_1,b_1,W_2,b_2,B]\n",
    "    variable_names=[v.name for v in tf.trainable_variables()]\n",
    "    #\n",
    "    #define transformation from input to output  \n",
    "  # Hidden Layer Transformation\n",
    "    g_hidden=tf.matmul(X, W_1) + b_1\n",
    "    hidden = tf.nn.relu(g_hidden)\n",
    "  # Output Layer Transformation\n",
    "    output = tf.matmul(hidden, W_2) + b_2\n",
    "    \n",
    "\n",
    "            ##################\n",
    "            ## kernl train ####\n",
    "            ##################\n",
    "    with tf.name_scope(\"kernl_train\") as scope:\n",
    "        loss = tf.losses.mean_squared_error(Y, output)\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(output, 1))\n",
    "        accuracy = 100 * tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        optimizer  = tf.train.AdamOptimizer(learning_rate=weight_learning_rate)\n",
    "  # compute and apply gradiants\n",
    "        dW_2=tf.reduce_mean(tf.transpose(tf.einsum('uv,un->uvn',tf.subtract(output,Y),(hidden))),axis=-1)\n",
    "        db_2=tf.reduce_mean(tf.subtract(output,Y),axis=0)\n",
    "        dg_hidden=drelu(g_hidden)\n",
    "        dg_hidden_diag=tf.linalg.diag(dg_hidden)\n",
    "        dW_1=tf.transpose(tf.reduce_mean(tf.einsum('uv,ug->uvg',tf.einsum('uv,uvg->ug',tf.einsum('un,nv->uv',tf.subtract(output,Y),B),dg_hidden_diag),X),axis=0))\n",
    "        db_1=tf.transpose(tf.reduce_mean(tf.einsum('uv,ug->ug',tf.einsum('un,nv->uv',tf.subtract(output,Y),B),dg_hidden),axis=0)) \n",
    "        # gradient for B\n",
    "        dB=tf.negative(tf.reduce_mean(tf.einsum('uv,uz->uvz',output,tf.subtract(hidden,tf.einsum('uv,vz->uz',output,B))),axis=0))\n",
    "        new_ffn_grads=list(zip([dW_1,db_1,dW_2,db_2,dB],trainables))\n",
    "        ffn_train_op=optimizer.apply_gradients(new_ffn_grads)\n",
    "        \n",
    "  \n",
    "    with tf.name_scope(\"evaluate\") as scope: \n",
    "        kernl_loss_cross_validiation=tf.losses.mean_squared_error(Y,output)\n",
    "        kernl_correct_pred_cross_val=tf.equal(tf.argmax(Y, 1), tf.argmax(output, 1))\n",
    "        kernl_accu_cross_validation=100 * tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    with tf.name_scope('cross_validation_summary') as scope: \n",
    "        tf.summary.scalar('cross_validation_loss',kernl_loss_cross_validiation+1e-10)\n",
    "        tf.summary.scalar('cross_validation_accu',kernl_accu_cross_validation+1e-10)\n",
    "      \n",
    "        kernl_evaluate_summary_op=tf.summary.merge_all(scope=\"cross_validation_summary\") \n",
    "        \n",
    "                ##################\n",
    "                # SUMMARIES ######\n",
    "                ##################\n",
    "                \n",
    "    with tf.name_scope(\"summaries\") as scope:\n",
    "                    # kernl kernel\n",
    "        tf.summary.histogram('kernl_hidd_W',W_1+1e-10)\n",
    "        tf.summary.histogram('return_B',B+1e-10)\n",
    "                    # kernl output weight\n",
    "        tf.summary.histogram('kernl_output_W',W_2+1e-10)\n",
    "                    # kernl output bias\n",
    "                    # kernl loss and accuracy\n",
    "        tf.summary.scalar('loss_output_prediction',loss+1e-10)\n",
    "        tf.summary.scalar('accuracy',accuracy+1e-10)\n",
    "        kernl_merged_summary_op=tf.summary.merge_all(scope=\"summaries\")          \n",
    "        \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['variable: ', 'Hidden_W:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (784, 1000)]\n",
      "['variable: ', 'Hidden_b:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (1000,)]\n",
      "['variable: ', 'Output_W:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (1000, 10)]\n",
      "['variable: ', 'Output_b:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (10,)]\n",
      "['variable: ', 'B:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (10, 1000)]\n"
     ]
    }
   ],
   "source": [
    "# verify initialization\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(graph=graph,) as sess : \n",
    "    sess.run(init)\n",
    "    values,trainable_vars = sess.run([variable_names,trainables])\n",
    "    for k, v in zip(variable_names,values):\n",
    "        print([\"variable: \" , k])\n",
    "        #print([\"value: \" , v])\n",
    "        print([\"variable: \" , np.unicode_.find(k,'output')]) \n",
    "        print([\"shape: \" , v.shape])\n",
    "        #print(v) training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "filelist = [ f for f in os.listdir(log_dir) if f.endswith(\".local\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(log_dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1,kernl train Loss: 7.653, kernl_accuracy : 16.000\n",
      "Epoch: 1, Batch: 26,kernl train Loss: 1.792, kernl_accuracy : 16.000\n",
      "Epoch: 1, cross validation loss :1.307, cross validation accuracy: 15.200\n",
      "Epoch: 2, Batch: 1,kernl train Loss: 1.429, kernl_accuracy : 8.000\n",
      "Epoch: 2, Batch: 26,kernl train Loss: 1.022, kernl_accuracy : 16.000\n",
      "Epoch: 2, cross validation loss :0.859, cross validation accuracy: 29.600\n",
      "Epoch: 3, Batch: 1,kernl train Loss: 0.735, kernl_accuracy : 24.000\n",
      "Epoch: 3, Batch: 26,kernl train Loss: 0.844, kernl_accuracy : 16.000\n",
      "Epoch: 3, cross validation loss :0.661, cross validation accuracy: 30.400\n",
      "Epoch: 4, Batch: 1,kernl train Loss: 0.589, kernl_accuracy : 28.000\n",
      "Epoch: 4, Batch: 26,kernl train Loss: 0.467, kernl_accuracy : 40.000\n",
      "Epoch: 4, cross validation loss :0.557, cross validation accuracy: 25.600\n",
      "Epoch: 5, Batch: 1,kernl train Loss: 0.622, kernl_accuracy : 32.000\n",
      "Epoch: 5, Batch: 26,kernl train Loss: 0.450, kernl_accuracy : 28.000\n",
      "Epoch: 5, cross validation loss :0.420, cross validation accuracy: 33.600\n",
      "Epoch: 6, Batch: 1,kernl train Loss: 0.489, kernl_accuracy : 24.000\n",
      "Epoch: 6, Batch: 26,kernl train Loss: 0.405, kernl_accuracy : 28.000\n",
      "Epoch: 6, cross validation loss :0.388, cross validation accuracy: 34.400\n",
      "Epoch: 7, Batch: 1,kernl train Loss: 0.578, kernl_accuracy : 44.000\n",
      "Epoch: 7, Batch: 26,kernl train Loss: 0.341, kernl_accuracy : 48.000\n",
      "Epoch: 7, cross validation loss :0.411, cross validation accuracy: 36.800\n",
      "Epoch: 8, Batch: 1,kernl train Loss: 0.355, kernl_accuracy : 40.000\n",
      "Epoch: 8, Batch: 26,kernl train Loss: 0.421, kernl_accuracy : 24.000\n",
      "Epoch: 8, cross validation loss :0.357, cross validation accuracy: 35.200\n",
      "Epoch: 9, Batch: 1,kernl train Loss: 0.308, kernl_accuracy : 68.000\n",
      "Epoch: 9, Batch: 26,kernl train Loss: 0.355, kernl_accuracy : 48.000\n",
      "Epoch: 9, cross validation loss :0.314, cross validation accuracy: 34.400\n",
      "Epoch: 10, Batch: 1,kernl train Loss: 0.362, kernl_accuracy : 52.000\n",
      "Epoch: 10, Batch: 26,kernl train Loss: 0.262, kernl_accuracy : 32.000\n",
      "Epoch: 10, cross validation loss :0.290, cross validation accuracy: 37.600\n",
      "Epoch: 11, Batch: 1,kernl train Loss: 0.327, kernl_accuracy : 28.000\n",
      "Epoch: 11, Batch: 26,kernl train Loss: 0.323, kernl_accuracy : 44.000\n",
      "Epoch: 11, cross validation loss :0.288, cross validation accuracy: 39.200\n",
      "Epoch: 12, Batch: 1,kernl train Loss: 0.250, kernl_accuracy : 52.000\n",
      "Epoch: 12, Batch: 26,kernl train Loss: 0.239, kernl_accuracy : 64.000\n",
      "Epoch: 12, cross validation loss :0.287, cross validation accuracy: 41.600\n",
      "Epoch: 13, Batch: 1,kernl train Loss: 0.293, kernl_accuracy : 40.000\n",
      "Epoch: 13, Batch: 26,kernl train Loss: 0.302, kernl_accuracy : 44.000\n",
      "Epoch: 13, cross validation loss :0.242, cross validation accuracy: 46.400\n",
      "Epoch: 14, Batch: 1,kernl train Loss: 0.245, kernl_accuracy : 48.000\n",
      "Epoch: 14, Batch: 26,kernl train Loss: 0.308, kernl_accuracy : 40.000\n",
      "Epoch: 14, cross validation loss :0.234, cross validation accuracy: 45.600\n",
      "Epoch: 15, Batch: 1,kernl train Loss: 0.253, kernl_accuracy : 52.000\n",
      "Epoch: 15, Batch: 26,kernl train Loss: 0.244, kernl_accuracy : 72.000\n",
      "Epoch: 15, cross validation loss :0.235, cross validation accuracy: 52.000\n",
      "Epoch: 16, Batch: 1,kernl train Loss: 0.276, kernl_accuracy : 52.000\n",
      "Epoch: 16, Batch: 26,kernl train Loss: 0.248, kernl_accuracy : 48.000\n",
      "Epoch: 16, cross validation loss :0.216, cross validation accuracy: 48.000\n",
      "Epoch: 17, Batch: 1,kernl train Loss: 0.195, kernl_accuracy : 48.000\n",
      "Epoch: 17, Batch: 26,kernl train Loss: 0.201, kernl_accuracy : 68.000\n",
      "Epoch: 17, cross validation loss :0.198, cross validation accuracy: 42.400\n",
      "Epoch: 18, Batch: 1,kernl train Loss: 0.244, kernl_accuracy : 60.000\n",
      "Epoch: 18, Batch: 26,kernl train Loss: 0.274, kernl_accuracy : 40.000\n",
      "Epoch: 18, cross validation loss :0.208, cross validation accuracy: 50.400\n",
      "Epoch: 19, Batch: 1,kernl train Loss: 0.241, kernl_accuracy : 56.000\n",
      "Epoch: 19, Batch: 26,kernl train Loss: 0.210, kernl_accuracy : 56.000\n",
      "Epoch: 19, cross validation loss :0.181, cross validation accuracy: 54.400\n",
      "Epoch: 20, Batch: 1,kernl train Loss: 0.181, kernl_accuracy : 56.000\n",
      "Epoch: 20, Batch: 26,kernl train Loss: 0.180, kernl_accuracy : 60.000\n",
      "Epoch: 20, cross validation loss :0.211, cross validation accuracy: 49.600\n",
      "Epoch: 21, Batch: 1,kernl train Loss: 0.191, kernl_accuracy : 64.000\n",
      "Epoch: 21, Batch: 26,kernl train Loss: 0.162, kernl_accuracy : 56.000\n",
      "Epoch: 21, cross validation loss :0.201, cross validation accuracy: 52.800\n",
      "Epoch: 22, Batch: 1,kernl train Loss: 0.231, kernl_accuracy : 56.000\n",
      "Epoch: 22, Batch: 26,kernl train Loss: 0.199, kernl_accuracy : 72.000\n",
      "Epoch: 22, cross validation loss :0.184, cross validation accuracy: 53.600\n",
      "Epoch: 23, Batch: 1,kernl train Loss: 0.180, kernl_accuracy : 60.000\n",
      "Epoch: 23, Batch: 26,kernl train Loss: 0.165, kernl_accuracy : 60.000\n",
      "Epoch: 23, cross validation loss :0.175, cross validation accuracy: 61.600\n",
      "Epoch: 24, Batch: 1,kernl train Loss: 0.179, kernl_accuracy : 84.000\n",
      "Epoch: 24, Batch: 26,kernl train Loss: 0.210, kernl_accuracy : 52.000\n",
      "Epoch: 24, cross validation loss :0.190, cross validation accuracy: 52.000\n",
      "Epoch: 25, Batch: 1,kernl train Loss: 0.208, kernl_accuracy : 56.000\n",
      "Epoch: 25, Batch: 26,kernl train Loss: 0.223, kernl_accuracy : 64.000\n",
      "Epoch: 25, cross validation loss :0.178, cross validation accuracy: 61.600\n",
      "Epoch: 26, Batch: 1,kernl train Loss: 0.187, kernl_accuracy : 60.000\n",
      "Epoch: 26, Batch: 26,kernl train Loss: 0.150, kernl_accuracy : 72.000\n",
      "Epoch: 26, cross validation loss :0.185, cross validation accuracy: 61.600\n",
      "Epoch: 27, Batch: 1,kernl train Loss: 0.165, kernl_accuracy : 56.000\n",
      "Epoch: 27, Batch: 26,kernl train Loss: 0.146, kernl_accuracy : 80.000\n",
      "Epoch: 27, cross validation loss :0.193, cross validation accuracy: 60.000\n",
      "Epoch: 28, Batch: 1,kernl train Loss: 0.205, kernl_accuracy : 52.000\n",
      "Epoch: 28, Batch: 26,kernl train Loss: 0.247, kernl_accuracy : 60.000\n",
      "Epoch: 28, cross validation loss :0.197, cross validation accuracy: 58.400\n",
      "Epoch: 29, Batch: 1,kernl train Loss: 0.189, kernl_accuracy : 48.000\n",
      "Epoch: 29, Batch: 26,kernl train Loss: 0.205, kernl_accuracy : 52.000\n",
      "Epoch: 29, cross validation loss :0.184, cross validation accuracy: 56.800\n",
      "Epoch: 30, Batch: 1,kernl train Loss: 0.231, kernl_accuracy : 48.000\n",
      "Epoch: 30, Batch: 26,kernl train Loss: 0.195, kernl_accuracy : 60.000\n",
      "Epoch: 30, cross validation loss :0.190, cross validation accuracy: 60.800\n",
      "Epoch: 31, Batch: 1,kernl train Loss: 0.201, kernl_accuracy : 60.000\n",
      "Epoch: 31, Batch: 26,kernl train Loss: 0.237, kernl_accuracy : 52.000\n",
      "Epoch: 31, cross validation loss :0.182, cross validation accuracy: 60.800\n",
      "Epoch: 32, Batch: 1,kernl train Loss: 0.169, kernl_accuracy : 76.000\n",
      "Epoch: 32, Batch: 26,kernl train Loss: 0.164, kernl_accuracy : 68.000\n",
      "Epoch: 32, cross validation loss :0.176, cross validation accuracy: 57.600\n",
      "Epoch: 33, Batch: 1,kernl train Loss: 0.151, kernl_accuracy : 60.000\n",
      "Epoch: 33, Batch: 26,kernl train Loss: 0.201, kernl_accuracy : 52.000\n",
      "Epoch: 33, cross validation loss :0.159, cross validation accuracy: 64.000\n",
      "Epoch: 34, Batch: 1,kernl train Loss: 0.164, kernl_accuracy : 68.000\n",
      "Epoch: 34, Batch: 26,kernl train Loss: 0.145, kernl_accuracy : 56.000\n",
      "Epoch: 34, cross validation loss :0.165, cross validation accuracy: 65.600\n",
      "Epoch: 35, Batch: 1,kernl train Loss: 0.183, kernl_accuracy : 60.000\n",
      "Epoch: 35, Batch: 26,kernl train Loss: 0.173, kernl_accuracy : 68.000\n",
      "Epoch: 35, cross validation loss :0.153, cross validation accuracy: 66.400\n",
      "Epoch: 36, Batch: 1,kernl train Loss: 0.144, kernl_accuracy : 76.000\n",
      "Epoch: 36, Batch: 26,kernl train Loss: 0.184, kernl_accuracy : 80.000\n",
      "Epoch: 36, cross validation loss :0.154, cross validation accuracy: 69.600\n",
      "Epoch: 37, Batch: 1,kernl train Loss: 0.182, kernl_accuracy : 56.000\n",
      "Epoch: 37, Batch: 26,kernl train Loss: 0.173, kernl_accuracy : 56.000\n",
      "Epoch: 37, cross validation loss :0.152, cross validation accuracy: 69.600\n",
      "Epoch: 38, Batch: 1,kernl train Loss: 0.167, kernl_accuracy : 52.000\n",
      "Epoch: 38, Batch: 26,kernl train Loss: 0.138, kernl_accuracy : 72.000\n",
      "Epoch: 38, cross validation loss :0.148, cross validation accuracy: 72.800\n",
      "Epoch: 39, Batch: 1,kernl train Loss: 0.160, kernl_accuracy : 64.000\n",
      "Epoch: 39, Batch: 26,kernl train Loss: 0.147, kernl_accuracy : 76.000\n",
      "Epoch: 39, cross validation loss :0.140, cross validation accuracy: 73.600\n",
      "Epoch: 40, Batch: 1,kernl train Loss: 0.177, kernl_accuracy : 64.000\n",
      "Epoch: 40, Batch: 26,kernl train Loss: 0.134, kernl_accuracy : 60.000\n",
      "Epoch: 40, cross validation loss :0.139, cross validation accuracy: 70.400\n",
      "Epoch: 41, Batch: 1,kernl train Loss: 0.137, kernl_accuracy : 80.000\n",
      "Epoch: 41, Batch: 26,kernl train Loss: 0.152, kernl_accuracy : 60.000\n",
      "Epoch: 41, cross validation loss :0.133, cross validation accuracy: 76.000\n",
      "Epoch: 42, Batch: 1,kernl train Loss: 0.154, kernl_accuracy : 64.000\n",
      "Epoch: 42, Batch: 26,kernl train Loss: 0.143, kernl_accuracy : 72.000\n",
      "Epoch: 42, cross validation loss :0.129, cross validation accuracy: 75.200\n",
      "Epoch: 43, Batch: 1,kernl train Loss: 0.138, kernl_accuracy : 84.000\n",
      "Epoch: 43, Batch: 26,kernl train Loss: 0.163, kernl_accuracy : 68.000\n",
      "Epoch: 43, cross validation loss :0.128, cross validation accuracy: 72.000\n",
      "Epoch: 44, Batch: 1,kernl train Loss: 0.158, kernl_accuracy : 68.000\n",
      "Epoch: 44, Batch: 26,kernl train Loss: 0.141, kernl_accuracy : 72.000\n",
      "Epoch: 44, cross validation loss :0.132, cross validation accuracy: 76.800\n",
      "Epoch: 45, Batch: 1,kernl train Loss: 0.102, kernl_accuracy : 80.000\n",
      "Epoch: 45, Batch: 26,kernl train Loss: 0.132, kernl_accuracy : 72.000\n",
      "Epoch: 45, cross validation loss :0.130, cross validation accuracy: 72.000\n",
      "Epoch: 46, Batch: 1,kernl train Loss: 0.133, kernl_accuracy : 84.000\n",
      "Epoch: 46, Batch: 26,kernl train Loss: 0.111, kernl_accuracy : 80.000\n",
      "Epoch: 46, cross validation loss :0.120, cross validation accuracy: 72.000\n",
      "Epoch: 47, Batch: 1,kernl train Loss: 0.119, kernl_accuracy : 80.000\n",
      "Epoch: 47, Batch: 26,kernl train Loss: 0.099, kernl_accuracy : 92.000\n",
      "Epoch: 47, cross validation loss :0.122, cross validation accuracy: 71.200\n",
      "Epoch: 48, Batch: 1,kernl train Loss: 0.111, kernl_accuracy : 72.000\n",
      "Epoch: 48, Batch: 26,kernl train Loss: 0.121, kernl_accuracy : 56.000\n",
      "Epoch: 48, cross validation loss :0.116, cross validation accuracy: 79.200\n",
      "Epoch: 49, Batch: 1,kernl train Loss: 0.118, kernl_accuracy : 68.000\n",
      "Epoch: 49, Batch: 26,kernl train Loss: 0.122, kernl_accuracy : 84.000\n",
      "Epoch: 49, cross validation loss :0.115, cross validation accuracy: 72.000\n",
      "Epoch: 50, Batch: 1,kernl train Loss: 0.086, kernl_accuracy : 92.000\n",
      "Epoch: 50, Batch: 26,kernl train Loss: 0.116, kernl_accuracy : 72.000\n",
      "Epoch: 50, cross validation loss :0.108, cross validation accuracy: 73.600\n",
      "Epoch: 51, Batch: 1,kernl train Loss: 0.092, kernl_accuracy : 96.000\n",
      "Epoch: 51, Batch: 26,kernl train Loss: 0.113, kernl_accuracy : 76.000\n",
      "Epoch: 51, cross validation loss :0.118, cross validation accuracy: 74.400\n",
      "Epoch: 52, Batch: 1,kernl train Loss: 0.106, kernl_accuracy : 80.000\n",
      "Epoch: 52, Batch: 26,kernl train Loss: 0.093, kernl_accuracy : 72.000\n",
      "Epoch: 52, cross validation loss :0.110, cross validation accuracy: 71.200\n",
      "Epoch: 53, Batch: 1,kernl train Loss: 0.140, kernl_accuracy : 68.000\n",
      "Epoch: 53, Batch: 26,kernl train Loss: 0.103, kernl_accuracy : 84.000\n",
      "Epoch: 53, cross validation loss :0.106, cross validation accuracy: 78.400\n",
      "Epoch: 54, Batch: 1,kernl train Loss: 0.107, kernl_accuracy : 84.000\n",
      "Epoch: 54, Batch: 26,kernl train Loss: 0.110, kernl_accuracy : 88.000\n",
      "Epoch: 54, cross validation loss :0.096, cross validation accuracy: 80.000\n",
      "Epoch: 55, Batch: 1,kernl train Loss: 0.105, kernl_accuracy : 80.000\n",
      "Epoch: 55, Batch: 26,kernl train Loss: 0.093, kernl_accuracy : 88.000\n",
      "Epoch: 55, cross validation loss :0.094, cross validation accuracy: 84.000\n",
      "Epoch: 56, Batch: 1,kernl train Loss: 0.130, kernl_accuracy : 76.000\n",
      "Epoch: 56, Batch: 26,kernl train Loss: 0.112, kernl_accuracy : 80.000\n",
      "Epoch: 56, cross validation loss :0.090, cross validation accuracy: 83.200\n",
      "Epoch: 57, Batch: 1,kernl train Loss: 0.085, kernl_accuracy : 88.000\n",
      "Epoch: 57, Batch: 26,kernl train Loss: 0.098, kernl_accuracy : 80.000\n",
      "Epoch: 57, cross validation loss :0.091, cross validation accuracy: 80.800\n",
      "Epoch: 58, Batch: 1,kernl train Loss: 0.113, kernl_accuracy : 64.000\n",
      "Epoch: 58, Batch: 26,kernl train Loss: 0.079, kernl_accuracy : 92.000\n",
      "Epoch: 58, cross validation loss :0.093, cross validation accuracy: 77.600\n",
      "Epoch: 59, Batch: 1,kernl train Loss: 0.097, kernl_accuracy : 72.000\n",
      "Epoch: 59, Batch: 26,kernl train Loss: 0.100, kernl_accuracy : 80.000\n",
      "Epoch: 59, cross validation loss :0.089, cross validation accuracy: 80.800\n",
      "Epoch: 60, Batch: 1,kernl train Loss: 0.096, kernl_accuracy : 80.000\n",
      "Epoch: 60, Batch: 26,kernl train Loss: 0.095, kernl_accuracy : 80.000\n",
      "Epoch: 60, cross validation loss :0.089, cross validation accuracy: 75.200\n",
      "Epoch: 61, Batch: 1,kernl train Loss: 0.102, kernl_accuracy : 80.000\n",
      "Epoch: 61, Batch: 26,kernl train Loss: 0.099, kernl_accuracy : 84.000\n",
      "Epoch: 61, cross validation loss :0.084, cross validation accuracy: 78.400\n",
      "Epoch: 62, Batch: 1,kernl train Loss: 0.081, kernl_accuracy : 96.000\n",
      "Epoch: 62, Batch: 26,kernl train Loss: 0.099, kernl_accuracy : 76.000\n",
      "Epoch: 62, cross validation loss :0.089, cross validation accuracy: 80.000\n",
      "Epoch: 63, Batch: 1,kernl train Loss: 0.081, kernl_accuracy : 84.000\n",
      "Epoch: 63, Batch: 26,kernl train Loss: 0.091, kernl_accuracy : 76.000\n",
      "Epoch: 63, cross validation loss :0.083, cross validation accuracy: 80.000\n",
      "Epoch: 64, Batch: 1,kernl train Loss: 0.078, kernl_accuracy : 72.000\n",
      "Epoch: 64, Batch: 26,kernl train Loss: 0.084, kernl_accuracy : 76.000\n",
      "Epoch: 64, cross validation loss :0.084, cross validation accuracy: 76.000\n",
      "Epoch: 65, Batch: 1,kernl train Loss: 0.068, kernl_accuracy : 84.000\n",
      "Epoch: 65, Batch: 26,kernl train Loss: 0.090, kernl_accuracy : 84.000\n",
      "Epoch: 65, cross validation loss :0.080, cross validation accuracy: 83.200\n",
      "Epoch: 66, Batch: 1,kernl train Loss: 0.084, kernl_accuracy : 88.000\n",
      "Epoch: 66, Batch: 26,kernl train Loss: 0.096, kernl_accuracy : 76.000\n",
      "Epoch: 66, cross validation loss :0.074, cross validation accuracy: 84.000\n",
      "Epoch: 67, Batch: 1,kernl train Loss: 0.073, kernl_accuracy : 80.000\n",
      "Epoch: 67, Batch: 26,kernl train Loss: 0.108, kernl_accuracy : 72.000\n",
      "Epoch: 67, cross validation loss :0.076, cross validation accuracy: 85.600\n",
      "Epoch: 68, Batch: 1,kernl train Loss: 0.091, kernl_accuracy : 76.000\n",
      "Epoch: 68, Batch: 26,kernl train Loss: 0.083, kernl_accuracy : 92.000\n",
      "Epoch: 68, cross validation loss :0.078, cross validation accuracy: 86.400\n",
      "Epoch: 69, Batch: 1,kernl train Loss: 0.096, kernl_accuracy : 84.000\n",
      "Epoch: 69, Batch: 26,kernl train Loss: 0.073, kernl_accuracy : 84.000\n",
      "Epoch: 69, cross validation loss :0.068, cross validation accuracy: 87.200\n",
      "Epoch: 70, Batch: 1,kernl train Loss: 0.054, kernl_accuracy : 96.000\n",
      "Epoch: 70, Batch: 26,kernl train Loss: 0.089, kernl_accuracy : 80.000\n",
      "Epoch: 70, cross validation loss :0.075, cross validation accuracy: 84.000\n",
      "Epoch: 71, Batch: 1,kernl train Loss: 0.078, kernl_accuracy : 80.000\n",
      "Epoch: 71, Batch: 26,kernl train Loss: 0.065, kernl_accuracy : 88.000\n",
      "Epoch: 71, cross validation loss :0.070, cross validation accuracy: 86.400\n",
      "Epoch: 72, Batch: 1,kernl train Loss: 0.082, kernl_accuracy : 68.000\n",
      "Epoch: 72, Batch: 26,kernl train Loss: 0.079, kernl_accuracy : 80.000\n",
      "Epoch: 72, cross validation loss :0.069, cross validation accuracy: 87.200\n",
      "Epoch: 73, Batch: 1,kernl train Loss: 0.073, kernl_accuracy : 84.000\n",
      "Epoch: 73, Batch: 26,kernl train Loss: 0.082, kernl_accuracy : 88.000\n",
      "Epoch: 73, cross validation loss :0.065, cross validation accuracy: 88.800\n",
      "Epoch: 74, Batch: 1,kernl train Loss: 0.075, kernl_accuracy : 84.000\n",
      "Epoch: 74, Batch: 26,kernl train Loss: 0.061, kernl_accuracy : 92.000\n",
      "Epoch: 74, cross validation loss :0.069, cross validation accuracy: 88.000\n",
      "Epoch: 75, Batch: 1,kernl train Loss: 0.087, kernl_accuracy : 88.000\n",
      "Epoch: 75, Batch: 26,kernl train Loss: 0.069, kernl_accuracy : 92.000\n",
      "Epoch: 75, cross validation loss :0.065, cross validation accuracy: 90.400\n",
      "Epoch: 76, Batch: 1,kernl train Loss: 0.087, kernl_accuracy : 80.000\n",
      "Epoch: 76, Batch: 26,kernl train Loss: 0.072, kernl_accuracy : 88.000\n",
      "Epoch: 76, cross validation loss :0.065, cross validation accuracy: 91.200\n",
      "Epoch: 77, Batch: 1,kernl train Loss: 0.071, kernl_accuracy : 84.000\n",
      "Epoch: 77, Batch: 26,kernl train Loss: 0.056, kernl_accuracy : 92.000\n",
      "Epoch: 77, cross validation loss :0.058, cross validation accuracy: 89.600\n",
      "Epoch: 78, Batch: 1,kernl train Loss: 0.068, kernl_accuracy : 88.000\n",
      "Epoch: 78, Batch: 26,kernl train Loss: 0.085, kernl_accuracy : 84.000\n",
      "Epoch: 78, cross validation loss :0.061, cross validation accuracy: 88.800\n",
      "Epoch: 79, Batch: 1,kernl train Loss: 0.078, kernl_accuracy : 76.000\n",
      "Epoch: 79, Batch: 26,kernl train Loss: 0.051, kernl_accuracy : 92.000\n",
      "Epoch: 79, cross validation loss :0.059, cross validation accuracy: 88.000\n",
      "Epoch: 80, Batch: 1,kernl train Loss: 0.073, kernl_accuracy : 88.000\n",
      "Epoch: 80, Batch: 26,kernl train Loss: 0.048, kernl_accuracy : 96.000\n",
      "Epoch: 80, cross validation loss :0.063, cross validation accuracy: 88.000\n",
      "Epoch: 81, Batch: 1,kernl train Loss: 0.064, kernl_accuracy : 80.000\n",
      "Epoch: 81, Batch: 26,kernl train Loss: 0.053, kernl_accuracy : 92.000\n",
      "Epoch: 81, cross validation loss :0.062, cross validation accuracy: 88.000\n",
      "Epoch: 82, Batch: 1,kernl train Loss: 0.064, kernl_accuracy : 76.000\n",
      "Epoch: 82, Batch: 26,kernl train Loss: 0.058, kernl_accuracy : 92.000\n",
      "Epoch: 82, cross validation loss :0.057, cross validation accuracy: 88.000\n",
      "Epoch: 83, Batch: 1,kernl train Loss: 0.059, kernl_accuracy : 88.000\n",
      "Epoch: 83, Batch: 26,kernl train Loss: 0.048, kernl_accuracy : 100.000\n",
      "Epoch: 83, cross validation loss :0.062, cross validation accuracy: 87.200\n",
      "Epoch: 84, Batch: 1,kernl train Loss: 0.050, kernl_accuracy : 96.000\n",
      "Epoch: 84, Batch: 26,kernl train Loss: 0.053, kernl_accuracy : 92.000\n",
      "Epoch: 84, cross validation loss :0.058, cross validation accuracy: 90.400\n",
      "Epoch: 85, Batch: 1,kernl train Loss: 0.050, kernl_accuracy : 96.000\n",
      "Epoch: 85, Batch: 26,kernl train Loss: 0.047, kernl_accuracy : 88.000\n",
      "Epoch: 85, cross validation loss :0.057, cross validation accuracy: 88.800\n",
      "Epoch: 86, Batch: 1,kernl train Loss: 0.062, kernl_accuracy : 88.000\n",
      "Epoch: 86, Batch: 26,kernl train Loss: 0.059, kernl_accuracy : 92.000\n",
      "Epoch: 86, cross validation loss :0.055, cross validation accuracy: 88.800\n",
      "Epoch: 87, Batch: 1,kernl train Loss: 0.060, kernl_accuracy : 92.000\n",
      "Epoch: 87, Batch: 26,kernl train Loss: 0.074, kernl_accuracy : 76.000\n",
      "Epoch: 87, cross validation loss :0.054, cross validation accuracy: 87.200\n",
      "Epoch: 88, Batch: 1,kernl train Loss: 0.062, kernl_accuracy : 84.000\n",
      "Epoch: 88, Batch: 26,kernl train Loss: 0.051, kernl_accuracy : 88.000\n",
      "Epoch: 88, cross validation loss :0.052, cross validation accuracy: 90.400\n",
      "Epoch: 89, Batch: 1,kernl train Loss: 0.055, kernl_accuracy : 84.000\n",
      "Epoch: 89, Batch: 26,kernl train Loss: 0.042, kernl_accuracy : 92.000\n",
      "Epoch: 89, cross validation loss :0.056, cross validation accuracy: 86.400\n",
      "Epoch: 90, Batch: 1,kernl train Loss: 0.064, kernl_accuracy : 84.000\n",
      "Epoch: 90, Batch: 26,kernl train Loss: 0.053, kernl_accuracy : 80.000\n",
      "Epoch: 90, cross validation loss :0.053, cross validation accuracy: 91.200\n",
      "Epoch: 91, Batch: 1,kernl train Loss: 0.050, kernl_accuracy : 88.000\n",
      "Epoch: 91, Batch: 26,kernl train Loss: 0.050, kernl_accuracy : 88.000\n",
      "Epoch: 91, cross validation loss :0.049, cross validation accuracy: 94.400\n",
      "Epoch: 92, Batch: 1,kernl train Loss: 0.049, kernl_accuracy : 92.000\n",
      "Epoch: 92, Batch: 26,kernl train Loss: 0.043, kernl_accuracy : 92.000\n",
      "Epoch: 92, cross validation loss :0.048, cross validation accuracy: 90.400\n",
      "Epoch: 93, Batch: 1,kernl train Loss: 0.049, kernl_accuracy : 84.000\n",
      "Epoch: 93, Batch: 26,kernl train Loss: 0.048, kernl_accuracy : 76.000\n",
      "Epoch: 93, cross validation loss :0.045, cross validation accuracy: 93.600\n",
      "Epoch: 94, Batch: 1,kernl train Loss: 0.050, kernl_accuracy : 88.000\n",
      "Epoch: 94, Batch: 26,kernl train Loss: 0.052, kernl_accuracy : 92.000\n",
      "Epoch: 94, cross validation loss :0.047, cross validation accuracy: 92.800\n",
      "Epoch: 95, Batch: 1,kernl train Loss: 0.046, kernl_accuracy : 100.000\n",
      "Epoch: 95, Batch: 26,kernl train Loss: 0.047, kernl_accuracy : 92.000\n",
      "Epoch: 95, cross validation loss :0.049, cross validation accuracy: 92.800\n",
      "Epoch: 96, Batch: 1,kernl train Loss: 0.043, kernl_accuracy : 96.000\n",
      "Epoch: 96, Batch: 26,kernl train Loss: 0.049, kernl_accuracy : 88.000\n",
      "Epoch: 96, cross validation loss :0.045, cross validation accuracy: 92.800\n",
      "Epoch: 97, Batch: 1,kernl train Loss: 0.040, kernl_accuracy : 96.000\n",
      "Epoch: 97, Batch: 26,kernl train Loss: 0.039, kernl_accuracy : 96.000\n",
      "Epoch: 97, cross validation loss :0.043, cross validation accuracy: 91.200\n",
      "Epoch: 98, Batch: 1,kernl train Loss: 0.037, kernl_accuracy : 96.000\n",
      "Epoch: 98, Batch: 26,kernl train Loss: 0.062, kernl_accuracy : 88.000\n",
      "Epoch: 98, cross validation loss :0.042, cross validation accuracy: 92.000\n",
      "Epoch: 99, Batch: 1,kernl train Loss: 0.033, kernl_accuracy : 100.000\n",
      "Epoch: 99, Batch: 26,kernl train Loss: 0.048, kernl_accuracy : 96.000\n",
      "Epoch: 99, cross validation loss :0.043, cross validation accuracy: 94.400\n",
      "Epoch: 100, Batch: 1,kernl train Loss: 0.052, kernl_accuracy : 92.000\n",
      "Epoch: 100, Batch: 26,kernl train Loss: 0.042, kernl_accuracy : 92.000\n",
      "Epoch: 100, cross validation loss :0.041, cross validation accuracy: 91.200\n",
      "Epoch: 101, Batch: 1,kernl train Loss: 0.037, kernl_accuracy : 96.000\n",
      "Epoch: 101, Batch: 26,kernl train Loss: 0.045, kernl_accuracy : 88.000\n",
      "Epoch: 101, cross validation loss :0.042, cross validation accuracy: 91.200\n",
      "Epoch: 102, Batch: 1,kernl train Loss: 0.050, kernl_accuracy : 88.000\n",
      "Epoch: 102, Batch: 26,kernl train Loss: 0.043, kernl_accuracy : 96.000\n",
      "Epoch: 102, cross validation loss :0.040, cross validation accuracy: 95.200\n",
      "Epoch: 103, Batch: 1,kernl train Loss: 0.043, kernl_accuracy : 88.000\n",
      "Epoch: 103, Batch: 26,kernl train Loss: 0.046, kernl_accuracy : 92.000\n",
      "Epoch: 103, cross validation loss :0.037, cross validation accuracy: 96.800\n",
      "Epoch: 104, Batch: 1,kernl train Loss: 0.032, kernl_accuracy : 100.000\n",
      "Epoch: 104, Batch: 26,kernl train Loss: 0.053, kernl_accuracy : 76.000\n",
      "Epoch: 104, cross validation loss :0.036, cross validation accuracy: 96.800\n",
      "Epoch: 105, Batch: 1,kernl train Loss: 0.030, kernl_accuracy : 96.000\n",
      "Epoch: 105, Batch: 26,kernl train Loss: 0.039, kernl_accuracy : 92.000\n",
      "Epoch: 105, cross validation loss :0.039, cross validation accuracy: 97.600\n",
      "Epoch: 106, Batch: 1,kernl train Loss: 0.041, kernl_accuracy : 92.000\n",
      "Epoch: 106, Batch: 26,kernl train Loss: 0.045, kernl_accuracy : 88.000\n",
      "Epoch: 106, cross validation loss :0.037, cross validation accuracy: 93.600\n",
      "Epoch: 107, Batch: 1,kernl train Loss: 0.041, kernl_accuracy : 100.000\n",
      "Epoch: 107, Batch: 26,kernl train Loss: 0.046, kernl_accuracy : 96.000\n",
      "Epoch: 107, cross validation loss :0.038, cross validation accuracy: 96.000\n",
      "Epoch: 108, Batch: 1,kernl train Loss: 0.046, kernl_accuracy : 88.000\n",
      "Epoch: 108, Batch: 26,kernl train Loss: 0.035, kernl_accuracy : 96.000\n",
      "Epoch: 108, cross validation loss :0.033, cross validation accuracy: 95.200\n",
      "Epoch: 109, Batch: 1,kernl train Loss: 0.029, kernl_accuracy : 96.000\n",
      "Epoch: 109, Batch: 26,kernl train Loss: 0.029, kernl_accuracy : 96.000\n",
      "Epoch: 109, cross validation loss :0.035, cross validation accuracy: 96.000\n",
      "Epoch: 110, Batch: 1,kernl train Loss: 0.031, kernl_accuracy : 92.000\n",
      "Epoch: 110, Batch: 26,kernl train Loss: 0.044, kernl_accuracy : 88.000\n",
      "Epoch: 110, cross validation loss :0.036, cross validation accuracy: 93.600\n",
      "Epoch: 111, Batch: 1,kernl train Loss: 0.038, kernl_accuracy : 96.000\n",
      "Epoch: 111, Batch: 26,kernl train Loss: 0.041, kernl_accuracy : 88.000\n",
      "Epoch: 111, cross validation loss :0.034, cross validation accuracy: 94.400\n",
      "Epoch: 112, Batch: 1,kernl train Loss: 0.046, kernl_accuracy : 84.000\n",
      "Epoch: 112, Batch: 26,kernl train Loss: 0.034, kernl_accuracy : 92.000\n",
      "Epoch: 112, cross validation loss :0.031, cross validation accuracy: 95.200\n",
      "Epoch: 113, Batch: 1,kernl train Loss: 0.023, kernl_accuracy : 100.000\n",
      "Epoch: 113, Batch: 26,kernl train Loss: 0.028, kernl_accuracy : 100.000\n",
      "Epoch: 113, cross validation loss :0.031, cross validation accuracy: 97.600\n",
      "Epoch: 114, Batch: 1,kernl train Loss: 0.034, kernl_accuracy : 96.000\n",
      "Epoch: 114, Batch: 26,kernl train Loss: 0.046, kernl_accuracy : 84.000\n",
      "Epoch: 114, cross validation loss :0.030, cross validation accuracy: 96.000\n",
      "Epoch: 115, Batch: 1,kernl train Loss: 0.043, kernl_accuracy : 92.000\n",
      "Epoch: 115, Batch: 26,kernl train Loss: 0.037, kernl_accuracy : 92.000\n",
      "Epoch: 115, cross validation loss :0.029, cross validation accuracy: 96.800\n",
      "Epoch: 116, Batch: 1,kernl train Loss: 0.036, kernl_accuracy : 88.000\n",
      "Epoch: 116, Batch: 26,kernl train Loss: 0.021, kernl_accuracy : 100.000\n",
      "Epoch: 116, cross validation loss :0.031, cross validation accuracy: 97.600\n",
      "Epoch: 117, Batch: 1,kernl train Loss: 0.033, kernl_accuracy : 92.000\n",
      "Epoch: 117, Batch: 26,kernl train Loss: 0.038, kernl_accuracy : 96.000\n",
      "Epoch: 117, cross validation loss :0.029, cross validation accuracy: 97.600\n",
      "Epoch: 118, Batch: 1,kernl train Loss: 0.028, kernl_accuracy : 100.000\n",
      "Epoch: 118, Batch: 26,kernl train Loss: 0.033, kernl_accuracy : 92.000\n",
      "Epoch: 118, cross validation loss :0.028, cross validation accuracy: 96.800\n",
      "Epoch: 119, Batch: 1,kernl train Loss: 0.029, kernl_accuracy : 96.000\n",
      "Epoch: 119, Batch: 26,kernl train Loss: 0.035, kernl_accuracy : 96.000\n",
      "Epoch: 119, cross validation loss :0.028, cross validation accuracy: 96.800\n",
      "Epoch: 120, Batch: 1,kernl train Loss: 0.023, kernl_accuracy : 100.000\n",
      "Epoch: 120, Batch: 26,kernl train Loss: 0.020, kernl_accuracy : 100.000\n",
      "Epoch: 120, cross validation loss :0.028, cross validation accuracy: 99.200\n",
      "Epoch: 121, Batch: 1,kernl train Loss: 0.027, kernl_accuracy : 96.000\n",
      "Epoch: 121, Batch: 26,kernl train Loss: 0.040, kernl_accuracy : 80.000\n",
      "Epoch: 121, cross validation loss :0.028, cross validation accuracy: 95.200\n",
      "Epoch: 122, Batch: 1,kernl train Loss: 0.028, kernl_accuracy : 92.000\n",
      "Epoch: 122, Batch: 26,kernl train Loss: 0.031, kernl_accuracy : 92.000\n",
      "Epoch: 122, cross validation loss :0.028, cross validation accuracy: 96.000\n",
      "Epoch: 123, Batch: 1,kernl train Loss: 0.037, kernl_accuracy : 96.000\n",
      "Epoch: 123, Batch: 26,kernl train Loss: 0.035, kernl_accuracy : 84.000\n",
      "Epoch: 123, cross validation loss :0.027, cross validation accuracy: 96.800\n",
      "Epoch: 124, Batch: 1,kernl train Loss: 0.031, kernl_accuracy : 96.000\n",
      "Epoch: 124, Batch: 26,kernl train Loss: 0.027, kernl_accuracy : 96.000\n",
      "Epoch: 124, cross validation loss :0.034, cross validation accuracy: 96.800\n",
      "Epoch: 125, Batch: 1,kernl train Loss: 0.027, kernl_accuracy : 100.000\n",
      "Epoch: 125, Batch: 26,kernl train Loss: 0.028, kernl_accuracy : 88.000\n",
      "Epoch: 125, cross validation loss :0.026, cross validation accuracy: 96.000\n",
      "Epoch: 126, Batch: 1,kernl train Loss: 0.022, kernl_accuracy : 100.000\n",
      "Epoch: 126, Batch: 26,kernl train Loss: 0.028, kernl_accuracy : 92.000\n",
      "Epoch: 126, cross validation loss :0.027, cross validation accuracy: 96.800\n",
      "Epoch: 127, Batch: 1,kernl train Loss: 0.028, kernl_accuracy : 92.000\n",
      "Epoch: 127, Batch: 26,kernl train Loss: 0.028, kernl_accuracy : 88.000\n",
      "Epoch: 127, cross validation loss :0.027, cross validation accuracy: 95.200\n",
      "Epoch: 128, Batch: 1,kernl train Loss: 0.027, kernl_accuracy : 96.000\n",
      "Epoch: 128, Batch: 26,kernl train Loss: 0.027, kernl_accuracy : 92.000\n",
      "Epoch: 128, cross validation loss :0.024, cross validation accuracy: 96.800\n",
      "Epoch: 129, Batch: 1,kernl train Loss: 0.035, kernl_accuracy : 84.000\n",
      "Epoch: 129, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 100.000\n",
      "Epoch: 129, cross validation loss :0.021, cross validation accuracy: 98.400\n",
      "Epoch: 130, Batch: 1,kernl train Loss: 0.041, kernl_accuracy : 84.000\n",
      "Epoch: 130, Batch: 26,kernl train Loss: 0.024, kernl_accuracy : 92.000\n",
      "Epoch: 130, cross validation loss :0.025, cross validation accuracy: 94.400\n",
      "Epoch: 131, Batch: 1,kernl train Loss: 0.024, kernl_accuracy : 100.000\n",
      "Epoch: 131, Batch: 26,kernl train Loss: 0.021, kernl_accuracy : 96.000\n",
      "Epoch: 131, cross validation loss :0.022, cross validation accuracy: 98.400\n",
      "Epoch: 132, Batch: 1,kernl train Loss: 0.022, kernl_accuracy : 92.000\n",
      "Epoch: 132, Batch: 26,kernl train Loss: 0.029, kernl_accuracy : 92.000\n",
      "Epoch: 132, cross validation loss :0.023, cross validation accuracy: 98.400\n",
      "Epoch: 133, Batch: 1,kernl train Loss: 0.023, kernl_accuracy : 100.000\n",
      "Epoch: 133, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 100.000\n",
      "Epoch: 133, cross validation loss :0.022, cross validation accuracy: 96.800\n",
      "Epoch: 134, Batch: 1,kernl train Loss: 0.020, kernl_accuracy : 96.000\n",
      "Epoch: 134, Batch: 26,kernl train Loss: 0.022, kernl_accuracy : 96.000\n",
      "Epoch: 134, cross validation loss :0.022, cross validation accuracy: 97.600\n",
      "Epoch: 135, Batch: 1,kernl train Loss: 0.024, kernl_accuracy : 100.000\n",
      "Epoch: 135, Batch: 26,kernl train Loss: 0.023, kernl_accuracy : 96.000\n",
      "Epoch: 135, cross validation loss :0.020, cross validation accuracy: 98.400\n",
      "Epoch: 136, Batch: 1,kernl train Loss: 0.021, kernl_accuracy : 96.000\n",
      "Epoch: 136, Batch: 26,kernl train Loss: 0.020, kernl_accuracy : 96.000\n",
      "Epoch: 136, cross validation loss :0.020, cross validation accuracy: 97.600\n",
      "Epoch: 137, Batch: 1,kernl train Loss: 0.019, kernl_accuracy : 92.000\n",
      "Epoch: 137, Batch: 26,kernl train Loss: 0.019, kernl_accuracy : 96.000\n",
      "Epoch: 137, cross validation loss :0.019, cross validation accuracy: 97.600\n",
      "Epoch: 138, Batch: 1,kernl train Loss: 0.023, kernl_accuracy : 92.000\n",
      "Epoch: 138, Batch: 26,kernl train Loss: 0.021, kernl_accuracy : 96.000\n",
      "Epoch: 138, cross validation loss :0.020, cross validation accuracy: 96.000\n",
      "Epoch: 139, Batch: 1,kernl train Loss: 0.021, kernl_accuracy : 100.000\n",
      "Epoch: 139, Batch: 26,kernl train Loss: 0.024, kernl_accuracy : 92.000\n",
      "Epoch: 139, cross validation loss :0.019, cross validation accuracy: 98.400\n",
      "Epoch: 140, Batch: 1,kernl train Loss: 0.024, kernl_accuracy : 96.000\n",
      "Epoch: 140, Batch: 26,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 140, cross validation loss :0.021, cross validation accuracy: 97.600\n",
      "Epoch: 141, Batch: 1,kernl train Loss: 0.021, kernl_accuracy : 96.000\n",
      "Epoch: 141, Batch: 26,kernl train Loss: 0.024, kernl_accuracy : 96.000\n",
      "Epoch: 141, cross validation loss :0.018, cross validation accuracy: 98.400\n",
      "Epoch: 142, Batch: 1,kernl train Loss: 0.019, kernl_accuracy : 96.000\n",
      "Epoch: 142, Batch: 26,kernl train Loss: 0.020, kernl_accuracy : 100.000\n",
      "Epoch: 142, cross validation loss :0.021, cross validation accuracy: 97.600\n",
      "Epoch: 143, Batch: 1,kernl train Loss: 0.019, kernl_accuracy : 92.000\n",
      "Epoch: 143, Batch: 26,kernl train Loss: 0.025, kernl_accuracy : 96.000\n",
      "Epoch: 143, cross validation loss :0.019, cross validation accuracy: 98.400\n",
      "Epoch: 144, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 144, Batch: 26,kernl train Loss: 0.015, kernl_accuracy : 100.000\n",
      "Epoch: 144, cross validation loss :0.017, cross validation accuracy: 98.400\n",
      "Epoch: 145, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 100.000\n",
      "Epoch: 145, Batch: 26,kernl train Loss: 0.016, kernl_accuracy : 100.000\n",
      "Epoch: 145, cross validation loss :0.017, cross validation accuracy: 98.400\n",
      "Epoch: 146, Batch: 1,kernl train Loss: 0.020, kernl_accuracy : 96.000\n",
      "Epoch: 146, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 100.000\n",
      "Epoch: 146, cross validation loss :0.022, cross validation accuracy: 97.600\n",
      "Epoch: 147, Batch: 1,kernl train Loss: 0.020, kernl_accuracy : 100.000\n",
      "Epoch: 147, Batch: 26,kernl train Loss: 0.012, kernl_accuracy : 100.000\n",
      "Epoch: 147, cross validation loss :0.018, cross validation accuracy: 99.200\n",
      "Epoch: 148, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 148, Batch: 26,kernl train Loss: 0.024, kernl_accuracy : 92.000\n",
      "Epoch: 148, cross validation loss :0.017, cross validation accuracy: 99.200\n",
      "Epoch: 149, Batch: 1,kernl train Loss: 0.017, kernl_accuracy : 96.000\n",
      "Epoch: 149, Batch: 26,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 149, cross validation loss :0.016, cross validation accuracy: 99.200\n",
      "Epoch: 150, Batch: 1,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 150, Batch: 26,kernl train Loss: 0.022, kernl_accuracy : 100.000\n",
      "Epoch: 150, cross validation loss :0.022, cross validation accuracy: 97.600\n",
      "Epoch: 151, Batch: 1,kernl train Loss: 0.024, kernl_accuracy : 100.000\n",
      "Epoch: 151, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 100.000\n",
      "Epoch: 151, cross validation loss :0.018, cross validation accuracy: 99.200\n",
      "Epoch: 152, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 100.000\n",
      "Epoch: 152, Batch: 26,kernl train Loss: 0.026, kernl_accuracy : 96.000\n",
      "Epoch: 152, cross validation loss :0.015, cross validation accuracy: 99.200\n",
      "Epoch: 153, Batch: 1,kernl train Loss: 0.010, kernl_accuracy : 100.000\n",
      "Epoch: 153, Batch: 26,kernl train Loss: 0.015, kernl_accuracy : 100.000\n",
      "Epoch: 153, cross validation loss :0.015, cross validation accuracy: 100.000\n",
      "Epoch: 154, Batch: 1,kernl train Loss: 0.011, kernl_accuracy : 100.000\n",
      "Epoch: 154, Batch: 26,kernl train Loss: 0.019, kernl_accuracy : 100.000\n",
      "Epoch: 154, cross validation loss :0.016, cross validation accuracy: 97.600\n",
      "Epoch: 155, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 155, Batch: 26,kernl train Loss: 0.019, kernl_accuracy : 100.000\n",
      "Epoch: 155, cross validation loss :0.016, cross validation accuracy: 97.600\n",
      "Epoch: 156, Batch: 1,kernl train Loss: 0.028, kernl_accuracy : 88.000\n",
      "Epoch: 156, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 96.000\n",
      "Epoch: 156, cross validation loss :0.017, cross validation accuracy: 99.200\n",
      "Epoch: 157, Batch: 1,kernl train Loss: 0.022, kernl_accuracy : 96.000\n",
      "Epoch: 157, Batch: 26,kernl train Loss: 0.025, kernl_accuracy : 92.000\n",
      "Epoch: 157, cross validation loss :0.017, cross validation accuracy: 99.200\n",
      "Epoch: 158, Batch: 1,kernl train Loss: 0.012, kernl_accuracy : 100.000\n",
      "Epoch: 158, Batch: 26,kernl train Loss: 0.017, kernl_accuracy : 100.000\n",
      "Epoch: 158, cross validation loss :0.018, cross validation accuracy: 98.400\n",
      "Epoch: 159, Batch: 1,kernl train Loss: 0.022, kernl_accuracy : 96.000\n",
      "Epoch: 159, Batch: 26,kernl train Loss: 0.020, kernl_accuracy : 96.000\n",
      "Epoch: 159, cross validation loss :0.015, cross validation accuracy: 98.400\n",
      "Epoch: 160, Batch: 1,kernl train Loss: 0.017, kernl_accuracy : 92.000\n",
      "Epoch: 160, Batch: 26,kernl train Loss: 0.017, kernl_accuracy : 100.000\n",
      "Epoch: 160, cross validation loss :0.018, cross validation accuracy: 98.400\n",
      "Epoch: 161, Batch: 1,kernl train Loss: 0.019, kernl_accuracy : 100.000\n",
      "Epoch: 161, Batch: 26,kernl train Loss: 0.020, kernl_accuracy : 92.000\n",
      "Epoch: 161, cross validation loss :0.014, cross validation accuracy: 99.200\n",
      "Epoch: 162, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 162, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 96.000\n",
      "Epoch: 162, cross validation loss :0.014, cross validation accuracy: 98.400\n",
      "Epoch: 163, Batch: 1,kernl train Loss: 0.017, kernl_accuracy : 92.000\n",
      "Epoch: 163, Batch: 26,kernl train Loss: 0.023, kernl_accuracy : 96.000\n",
      "Epoch: 163, cross validation loss :0.015, cross validation accuracy: 97.600\n",
      "Epoch: 164, Batch: 1,kernl train Loss: 0.018, kernl_accuracy : 92.000\n",
      "Epoch: 164, Batch: 26,kernl train Loss: 0.013, kernl_accuracy : 96.000\n",
      "Epoch: 164, cross validation loss :0.014, cross validation accuracy: 97.600\n",
      "Epoch: 165, Batch: 1,kernl train Loss: 0.023, kernl_accuracy : 92.000\n",
      "Epoch: 165, Batch: 26,kernl train Loss: 0.019, kernl_accuracy : 96.000\n",
      "Epoch: 165, cross validation loss :0.014, cross validation accuracy: 98.400\n",
      "Epoch: 166, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 166, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 100.000\n",
      "Epoch: 166, cross validation loss :0.015, cross validation accuracy: 99.200\n",
      "Epoch: 167, Batch: 1,kernl train Loss: 0.015, kernl_accuracy : 96.000\n",
      "Epoch: 167, Batch: 26,kernl train Loss: 0.012, kernl_accuracy : 100.000\n",
      "Epoch: 167, cross validation loss :0.016, cross validation accuracy: 98.400\n",
      "Epoch: 168, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 168, Batch: 26,kernl train Loss: 0.021, kernl_accuracy : 92.000\n",
      "Epoch: 168, cross validation loss :0.015, cross validation accuracy: 97.600\n",
      "Epoch: 169, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 169, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 96.000\n",
      "Epoch: 169, cross validation loss :0.016, cross validation accuracy: 96.800\n",
      "Epoch: 170, Batch: 1,kernl train Loss: 0.013, kernl_accuracy : 96.000\n",
      "Epoch: 170, Batch: 26,kernl train Loss: 0.020, kernl_accuracy : 96.000\n",
      "Epoch: 170, cross validation loss :0.015, cross validation accuracy: 96.800\n",
      "Epoch: 171, Batch: 1,kernl train Loss: 0.017, kernl_accuracy : 92.000\n",
      "Epoch: 171, Batch: 26,kernl train Loss: 0.019, kernl_accuracy : 92.000\n",
      "Epoch: 171, cross validation loss :0.014, cross validation accuracy: 98.400\n",
      "Epoch: 172, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 172, Batch: 26,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 172, cross validation loss :0.014, cross validation accuracy: 98.400\n",
      "Epoch: 173, Batch: 1,kernl train Loss: 0.012, kernl_accuracy : 100.000\n",
      "Epoch: 173, Batch: 26,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 173, cross validation loss :0.013, cross validation accuracy: 98.400\n",
      "Epoch: 174, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 174, Batch: 26,kernl train Loss: 0.017, kernl_accuracy : 92.000\n",
      "Epoch: 174, cross validation loss :0.014, cross validation accuracy: 97.600\n",
      "Epoch: 175, Batch: 1,kernl train Loss: 0.021, kernl_accuracy : 92.000\n",
      "Epoch: 175, Batch: 26,kernl train Loss: 0.015, kernl_accuracy : 100.000\n",
      "Epoch: 175, cross validation loss :0.015, cross validation accuracy: 98.400\n",
      "Epoch: 176, Batch: 1,kernl train Loss: 0.018, kernl_accuracy : 100.000\n",
      "Epoch: 176, Batch: 26,kernl train Loss: 0.017, kernl_accuracy : 92.000\n",
      "Epoch: 176, cross validation loss :0.015, cross validation accuracy: 97.600\n",
      "Epoch: 177, Batch: 1,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 177, Batch: 26,kernl train Loss: 0.013, kernl_accuracy : 96.000\n",
      "Epoch: 177, cross validation loss :0.013, cross validation accuracy: 97.600\n",
      "Epoch: 178, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 100.000\n",
      "Epoch: 178, Batch: 26,kernl train Loss: 0.015, kernl_accuracy : 100.000\n",
      "Epoch: 178, cross validation loss :0.013, cross validation accuracy: 99.200\n",
      "Epoch: 179, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 100.000\n",
      "Epoch: 179, Batch: 26,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 179, cross validation loss :0.013, cross validation accuracy: 99.200\n",
      "Epoch: 180, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 96.000\n",
      "Epoch: 180, Batch: 26,kernl train Loss: 0.015, kernl_accuracy : 96.000\n",
      "Epoch: 180, cross validation loss :0.014, cross validation accuracy: 97.600\n",
      "Epoch: 181, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 96.000\n",
      "Epoch: 181, Batch: 26,kernl train Loss: 0.012, kernl_accuracy : 100.000\n",
      "Epoch: 181, cross validation loss :0.014, cross validation accuracy: 96.800\n",
      "Epoch: 182, Batch: 1,kernl train Loss: 0.014, kernl_accuracy : 96.000\n",
      "Epoch: 182, Batch: 26,kernl train Loss: 0.012, kernl_accuracy : 100.000\n",
      "Epoch: 182, cross validation loss :0.014, cross validation accuracy: 98.400\n",
      "Epoch: 183, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 183, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 92.000\n",
      "Epoch: 183, cross validation loss :0.013, cross validation accuracy: 99.200\n",
      "Epoch: 184, Batch: 1,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 184, Batch: 26,kernl train Loss: 0.015, kernl_accuracy : 100.000\n",
      "Epoch: 184, cross validation loss :0.014, cross validation accuracy: 97.600\n",
      "Epoch: 185, Batch: 1,kernl train Loss: 0.021, kernl_accuracy : 92.000\n",
      "Epoch: 185, Batch: 26,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 185, cross validation loss :0.012, cross validation accuracy: 97.600\n",
      "Epoch: 186, Batch: 1,kernl train Loss: 0.011, kernl_accuracy : 100.000\n",
      "Epoch: 186, Batch: 26,kernl train Loss: 0.020, kernl_accuracy : 96.000\n",
      "Epoch: 186, cross validation loss :0.013, cross validation accuracy: 99.200\n",
      "Epoch: 187, Batch: 1,kernl train Loss: 0.008, kernl_accuracy : 100.000\n",
      "Epoch: 187, Batch: 26,kernl train Loss: 0.011, kernl_accuracy : 100.000\n",
      "Epoch: 187, cross validation loss :0.013, cross validation accuracy: 96.800\n",
      "Epoch: 188, Batch: 1,kernl train Loss: 0.009, kernl_accuracy : 100.000\n",
      "Epoch: 188, Batch: 26,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 188, cross validation loss :0.012, cross validation accuracy: 98.400\n",
      "Epoch: 189, Batch: 1,kernl train Loss: 0.009, kernl_accuracy : 100.000\n",
      "Epoch: 189, Batch: 26,kernl train Loss: 0.021, kernl_accuracy : 88.000\n",
      "Epoch: 189, cross validation loss :0.013, cross validation accuracy: 98.400\n",
      "Epoch: 190, Batch: 1,kernl train Loss: 0.019, kernl_accuracy : 96.000\n",
      "Epoch: 190, Batch: 26,kernl train Loss: 0.011, kernl_accuracy : 100.000\n",
      "Epoch: 190, cross validation loss :0.012, cross validation accuracy: 100.000\n",
      "Epoch: 191, Batch: 1,kernl train Loss: 0.018, kernl_accuracy : 92.000\n",
      "Epoch: 191, Batch: 26,kernl train Loss: 0.016, kernl_accuracy : 100.000\n",
      "Epoch: 191, cross validation loss :0.013, cross validation accuracy: 97.600\n",
      "Epoch: 192, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 192, Batch: 26,kernl train Loss: 0.015, kernl_accuracy : 96.000\n",
      "Epoch: 192, cross validation loss :0.013, cross validation accuracy: 99.200\n",
      "Epoch: 193, Batch: 1,kernl train Loss: 0.009, kernl_accuracy : 100.000\n",
      "Epoch: 193, Batch: 26,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 193, cross validation loss :0.012, cross validation accuracy: 98.400\n",
      "Epoch: 194, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 92.000\n",
      "Epoch: 194, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 100.000\n",
      "Epoch: 194, cross validation loss :0.013, cross validation accuracy: 99.200\n",
      "Epoch: 195, Batch: 1,kernl train Loss: 0.012, kernl_accuracy : 96.000\n",
      "Epoch: 195, Batch: 26,kernl train Loss: 0.012, kernl_accuracy : 100.000\n",
      "Epoch: 195, cross validation loss :0.014, cross validation accuracy: 98.400\n",
      "Epoch: 196, Batch: 1,kernl train Loss: 0.011, kernl_accuracy : 100.000\n",
      "Epoch: 196, Batch: 26,kernl train Loss: 0.014, kernl_accuracy : 100.000\n",
      "Epoch: 196, cross validation loss :0.013, cross validation accuracy: 96.800\n",
      "Epoch: 197, Batch: 1,kernl train Loss: 0.011, kernl_accuracy : 96.000\n",
      "Epoch: 197, Batch: 26,kernl train Loss: 0.012, kernl_accuracy : 96.000\n",
      "Epoch: 197, cross validation loss :0.011, cross validation accuracy: 98.400\n",
      "Epoch: 198, Batch: 1,kernl train Loss: 0.015, kernl_accuracy : 96.000\n",
      "Epoch: 198, Batch: 26,kernl train Loss: 0.008, kernl_accuracy : 100.000\n",
      "Epoch: 198, cross validation loss :0.013, cross validation accuracy: 98.400\n",
      "Epoch: 199, Batch: 1,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 199, Batch: 26,kernl train Loss: 0.013, kernl_accuracy : 100.000\n",
      "Epoch: 199, cross validation loss :0.013, cross validation accuracy: 97.600\n",
      "Epoch: 200, Batch: 1,kernl train Loss: 0.016, kernl_accuracy : 96.000\n",
      "Epoch: 200, Batch: 26,kernl train Loss: 0.018, kernl_accuracy : 96.000\n",
      "Epoch: 200, cross validation loss :0.012, cross validation accuracy: 98.400\n",
      "Optimization Finished!\n",
      "Model saved in path: /home/eghbal/MyData/KeRNL/logs/ffn/kernl_mnist_eta_weight_1e-03_batch_2e+01_hum_hidd_1e+03_steps_5e+01_run_20190304_0953/model.ckpt-49\n"
     ]
    }
   ],
   "source": [
    "# write graph into tensorboard \n",
    "tb_writer = tf.summary.FileWriter(log_dir,graph)\n",
    "# run a training session \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(EPOCHS):\n",
    "        for step in range(NUM_TRAINING_STEPS): \n",
    "            batch_x, batch_y = mnist.train.next_batch(BATCH_SIZE)\n",
    "            _, kernl_loss,kernl_accu,kernl_merged_summary=sess.run([ffn_train_op,loss,accuracy,kernl_merged_summary_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "            tb_writer.add_summary(kernl_merged_summary, global_step=epoch*NUM_TRAINING_STEPS+step+1)\n",
    "\n",
    "            if step % DISPLAY_STEP==0 : \n",
    "                print('Epoch: {}, Batch: {},kernl train Loss: {:.3f}, kernl_accuracy : {:.3f}'.format(epoch+1,step + 1, kernl_loss,kernl_accu))\n",
    "                \n",
    "        # run test at the end of each epoch \n",
    "        test_x=mnist.test.images[:TEST_LENGTH]\n",
    "        test_y=mnist.test.labels[:TEST_LENGTH]  \n",
    "        kernl_test_loss,kernl_test_accu, kernl_evaluate_summary=sess.run([kernl_loss_cross_validiation,kernl_accu_cross_validation,kernl_evaluate_summary_op], feed_dict={X: test_x, Y: test_y})        \n",
    "        tb_writer.add_summary(kernl_evaluate_summary, global_step=epoch*NUM_TRAINING_STEPS+NUM_TRAINING_STEPS+1)\n",
    "        print('Epoch: {}, cross validation loss :{:.3f}, cross validation accuracy: {:.3f}'.format(epoch+1,kernl_test_loss,kernl_test_accu))\n",
    "            \n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    save_path = saver.save(sess, log_dir+\"/model.ckpt\", global_step=step,write_meta_graph=True)\n",
    "    print(\"Model saved in path: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
