{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes about the implementation \n",
    "-  both input and recurrent weight are combined into 1 kernel matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import hashlib\n",
    "import numbers\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import long_short_term_spike_cell_test_v3 as spiking_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first testing the code on a constant input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sequence_length = 150\n",
    "num_inputs=1\n",
    "num_units=1\n",
    "#shape=(2, 5, 2)\n",
    "input_spikes=np.random.randint(2,size=[batch_size,sequence_length,num_inputs])\n",
    "#input_spikes=np.ones([batch_size,sequence_length,num_inputs])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf_input_values = tf.constant(input_spikes, dtype=tf.float32)\n",
    "LSNN_cell = spiking_cell.long_short_term_spike_cell(num_units=num_units,num_inputs=num_inputs,state_is_tuple=True,output_is_tuple=True,\n",
    "                    kernel_initializer=tf.initializers.random_uniform())\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=LSNN_cell, dtype=tf.float32, inputs=tf_input_values)\n",
    "\n",
    "cell_outputs=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_run , state_run = sess.run([outputs, state])\n",
    "    variables_names =[v.name for v in tf.global_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k, v) \n",
    "plt.figure(figsize=[15,10])\n",
    "ax=plt.subplot(6,1,1)\n",
    "ax.plot(output_run.v_mem.flatten())\n",
    "ax.set_title('v_mem')\n",
    "ax=plt.subplot(6,1,2)\n",
    "ax.plot(output_run.spike.flatten())\n",
    "ax.set_title('spikes')\n",
    "ax=plt.subplot(6,1,3)\n",
    "ax.plot(input_spikes.flatten())\n",
    "ax.set_title('input_current')\n",
    "ax=plt.subplot(6,1,4)\n",
    "ax.plot(np.squeeze(output_run.S_rec,axis=0)[:,0,0])\n",
    "ax.set_title('S_rec')\n",
    "ax=plt.subplot(6,1,5)\n",
    "ax.plot(np.squeeze(output_run.S_in,axis=0)[:,0,0])\n",
    "ax.set_title('S_in')\n",
    "ax=plt.subplot(6,1,6)\n",
    "ax.plot(output_run.I_syn.flatten())\n",
    "ax.set_title('I_syn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "sequence_length = 70\n",
    "num_inputs=1\n",
    "num_units=2\n",
    "#shape=(2, 5, 2)\n",
    "input_spikes=np.random.randint(2,size=[batch_size,sequence_length,num_inputs])\n",
    "#input_spikes=np.ones([batch_size,sequence_length,num_inputs])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf_input_values = tf.constant(input_spikes, dtype=tf.float32)\n",
    "LSNN_cell = spiking_cell.long_short_term_spike_cell(num_units=num_units,num_inputs=num_inputs,state_is_tuple=True,output_is_tuple=True,\n",
    "                    kernel_initializer=tf.initializers.random_normal())\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=LSNN_cell, dtype=tf.float32, inputs=tf_input_values)\n",
    "\n",
    "cell_outputs=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_run , state_run = sess.run([outputs, state])\n",
    "    variables_names =[v.name for v in tf.global_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k, v) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we create a recurrent version to verify the functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sequence_length = 70\n",
    "num_inputs=1\n",
    "num_units=2\n",
    "#shape=(2, 5, 2)\n",
    "input_spikes=np.random.randint(2,size=[batch_size,sequence_length,num_inputs])\n",
    "#input_spikes=np.ones([batch_size,sequence_length,num_inputs])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf_input_values = tf.constant(input_spikes, dtype=tf.float32)\n",
    "LSNN_cell = spiking_cell.long_short_term_spike_cell(num_units=num_units,num_inputs=num_inputs,state_is_tuple=True,output_is_tuple=True,\n",
    "                    kernel_initializer=tf.initializers.random_normal())\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=LSNN_cell, dtype=tf.float32, inputs=tf_input_values)\n",
    "\n",
    "cell_outputs=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_run , state_run = sess.run([outputs, state])\n",
    "    variables_names =[v.name for v in tf.global_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k, v) \n",
    "plt.figure(figsize=[15,10])\n",
    "ax=plt.subplot(5,1,1)\n",
    "ax.plot(np.squeeze(output_run.v_mem,axis=0))\n",
    "ax.set_title('v_mem')\n",
    "ax=plt.subplot(5,1,2)\n",
    "ax.plot(np.squeeze(output_run.spike,axis=0))\n",
    "ax.set_title('spikes')\n",
    "ax=plt.subplot(5,1,3)\n",
    "ax.plot(np.squeeze(output_run.S_rec,axis=0)[:,:,0])\n",
    "ax.set_title('S_rec')\n",
    "ax=plt.subplot(5,1,4)\n",
    "ax.plot(np.squeeze(output_run.S_in,axis=0)[:,:,0])\n",
    "ax.set_title('S_rec')\n",
    "ax=plt.subplot(5,1,5)\n",
    "ax.plot(np.squeeze(output_run.I_syn,axis=0))\n",
    "ax.set_title('I_syn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "sequence_length = 70\n",
    "num_inputs=2\n",
    "num_units=2\n",
    "#shape=(2, 5, 2)\n",
    "input_spikes=np.random.randint(2,size=[batch_size,sequence_length,num_inputs])\n",
    "#input_spikes=np.ones([batch_size,sequence_length,num_inputs])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf_input_values = tf.constant(input_spikes, dtype=tf.float32)\n",
    "LSNN_cell = long_short_term_spike_cell(num_units=num_units,num_inputs=num_inputs,state_is_tuple=True,output_is_tuple=True,\n",
    "                    kernel_initializer=tf.initializers.ones())\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=LSNN_cell, dtype=tf.float32, inputs=tf_input_values)\n",
    "\n",
    "cell_outputs=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_run , state_run = sess.run([outputs, state])\n",
    "    variables_names =[v.name for v in tf.global_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k, v) \n",
    "\n",
    "v_mem=output_run.v_mem[3,:,:]\n",
    "spike=output_run.spike[3,:,:]\n",
    "I_rec=output_run.I_rec[3,:,:]\n",
    "I_in=output_run.I_in[3,:,:]\n",
    "plt.figure(figsize=[15,10])\n",
    "ax=plt.subplot(5,1,1)\n",
    "ax.plot((v_mem))\n",
    "ax.set_title('v_mem')\n",
    "ax=plt.subplot(5,1,2)\n",
    "ax.plot(spike)\n",
    "ax.set_title('spikes')\n",
    "ax=plt.subplot(5,1,3)\n",
    "ax.plot(I_rec)\n",
    "ax.set_title('I_rec')\n",
    "ax=plt.subplot(5,1,5)\n",
    "ax.plot(I_in)\n",
    "ax.set_title('I_in')\n",
    "ax=plt.subplot(5,1,4)\n",
    "ax.plot(input_spikes[3,:,:])\n",
    "ax.set_title('input_current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
