{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for implementing adding learning on snn with backpropagation \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n",
    "This code implements a spiking neural net with conductance in input. the following equations govern the dynamic of the network. \n",
    "### transmembrane voltage dynamics\n",
    "first we model the transmembrane voltage as \n",
    "$$\\tau_m \\frac{dV_i}{dt}= - V_i(t)+ R_m \\times I^{syn}_i(t) $$ \n",
    "$$ {\\tau_a}_i \\frac{dB_i(t)}{dt} = b_i^0 -B_i(t)$$ \n",
    "where, $R_m$ is membrane resistance, $\\tau_m$ is membrane time constant, and ${\\tau_a}_i$ is adaptation time constant  .\n",
    "the synaptic current relates to synaptic activations in the following way\n",
    "$$I^{syn}_i(t)= \\sum_j W^{in}_{ij} \\times X(t) + \\sum_j W^{rec}_{ij} \\times S_j(t) $$ \n",
    "\n",
    "### neuron firing dynamics \n",
    "The firing dynamics of the neuron is model as a simple reseting. More specifically, \n",
    "$$V_i \\rightarrow V_{reset} \\ \\ \\  if \\ \\ \\ V_i>=B_{i} $$\n",
    "\n",
    "$ V_{\\Theta}$ represent the threshold voltage and $V_{reset}$ is the reset voltage of the neuron.\n",
    "\n",
    "### Input dynamics \n",
    "Input synapes are the the site of learning in the spiking network. Below a conductance based formulation is presented. \n",
    "First, the time-dependent input conductance to membrane is calculated as follows \n",
    "$$ g_i(t) = \\sum_j W_{ij} S_{j}(t) $$\n",
    "\n",
    "in the current version $S_{j}(t)$ is equal to spike at timestep $t$ without any decay dynamics. \n",
    "-  TODO the term $j$ reperesent all the neurons that have a synapse onto the neuron $i$. the time dependence of conductance is due to $S(t)$ which represent the spiking activity for neurons connected to neuron $i$ . The spiking activity has the following governing equations \n",
    "$$ S_{j} \\rightarrow S_{j}+1 \\quad if \\ neuron\\ j\\ fires$$\n",
    "$$ \\frac{dS_{j}(t)}{dt} = \\frac{-S_{j}(t)}{\\tau_s}$$ \n",
    "\n",
    "### Spike Adaptation dynamics \n",
    "The threshold for spiking increases with every spike emited from a neuron with the following dynamics \n",
    "$$ B_{i}(t) \\rightarrow B_{i}(t)+\\frac{\\beta}{{\\tau_a}_i} \\quad if \\ neuron\\ i\\ fires$$\n",
    "\n",
    "\n",
    "### implementation in discrete time \n",
    "we start with Euler method for modeling the dynamics \n",
    "### References \n",
    "-  Fiete, Ila R., Walter Senn, Claude Z. H. Wang, and Richard H. R. Hahnloser. 2010. “Spike-Time-Dependent Plasticity and Heterosynaptic Competition Organize Networks to Produce Long Scale-Free Sequences of Neural Activity.” Neuron 65 (4): 563–76. \n",
    "\n",
    "-  Bellec, Guillaume, Darjan Salaj, Anand Subramoney, Robert Legenstein, and Wolfgang Maass. 2018. “Long Short-Term Memory and Learning-to-Learn in Networks of Spiking Neurons.” arXiv [cs.NE]. arXiv. http://arxiv.org/abs/1803.09574.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import collections\n",
    "import hashlib\n",
    "import numbers\n",
    "import matplotlib.cm as cm\n",
    "from sys import getsizeof\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "import re\n",
    "\n",
    "# tensorflow and its dependencies \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.layers import base as base_layer\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import partitioned_variables\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import variables as tf_variables\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell import _Linear\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "## user defined modules \n",
    "# kernel rnn cell \n",
    "import spiking_cell_bare as spiking_cell\n",
    "import adding_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial parameters for the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "weight_learning_rate = 1e-5\n",
    "training_steps = 5000\n",
    "batch_size = 25\n",
    "display_step = 50\n",
    "grad_clip=200\n",
    "# Network Parameters\n",
    "# 1-input layer \n",
    "num_input = 2 # \n",
    "time_steps = 100 # timesteps\n",
    "# 2-hidden layer \n",
    "num_hidden = 100 # hidden layer num of features\n",
    "# 3-output layer \n",
    "num_output = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bptt_snn_all_states(x):\n",
    "    with tf.variable_scope('hidden_layer') as scope: \n",
    "        hidden_layer_cell=spiking_cell.conductance_spike_cell(num_units=num_hidden,output_is_tuple=True,tau_refract=1.0,tau_m=20.0)\n",
    "        hidden_initial_state = hidden_layer_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        output_hidden, states_hidden = tf.nn.dynamic_rnn(hidden_layer_cell, dtype=tf.float32, inputs=x,initial_state=hidden_initial_state)\n",
    "    with tf.variable_scope('output_layer') as scope : \n",
    "        output_layer_cell=spiking_cell.output_spike_cell(num_units=num_output)\n",
    "        output_voltage, voltage_states=tf.nn.dynamic_rnn(output_layer_cell,dtype=tf.float32,inputs=output_hidden.spike)\n",
    "    return output_voltage,output_hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation graph backpropagation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    # check hardware \n",
    "    # define weights and inputs to the network\n",
    "    X = tf.placeholder(\"float\", [None, time_steps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_output])\n",
    "   \n",
    "    bptt_output,bptt_hidden_states=bptt_snn_all_states(X)\n",
    "    \n",
    "    trainables=tf.trainable_variables()\n",
    "    variable_names=[v.name for v in tf.trainable_variables()]\n",
    "    # \n",
    "    bptt_loss_output_prediction=tf.losses.mean_squared_error(Y,bptt_output[:,-1,:])\n",
    "    find_joing_index = lambda x, name_1,name_2 : [a and b for a,b in zip([np.unicode_.find(k.name, name_1)>-1 for k in x] ,[np.unicode_.find(k.name, name_2)>-1 for k in x])].index(True)\n",
    "    # find trainable parameters for bptt \n",
    "    with tf.name_scope('bptt_Trainables') as scope:\n",
    "        bptt_output_weight_index= find_joing_index(trainables,'output_layer','kernel')\n",
    "        bptt_kernel_index= find_joing_index(trainables,'hidden_layer','kernel')\n",
    "    #\n",
    "        bptt_weight_training_indices=np.asarray([bptt_kernel_index,bptt_output_weight_index],dtype=np.int)\n",
    "        bptt_weight_trainables= [trainables[k] for k in bptt_weight_training_indices]\n",
    "        \n",
    "    with tf.name_scope('bptt_train_weights') as scope: \n",
    "        bptt_weight_optimizer = tf.train.RMSPropOptimizer(learning_rate=weight_learning_rate)\n",
    "        bptt_loss_output_prediction=tf.losses.mean_squared_error(Y,bptt_output[:,-1,:])\n",
    "        bptt_grad_cost_trainables=tf.gradients(bptt_loss_output_prediction,bptt_weight_trainables)\n",
    "        bptt_weight_grads_and_vars=list(zip(bptt_grad_cost_trainables,bptt_weight_trainables))\n",
    "        bptt_cropped_weight_grads_and_vars=[(tf.clip_by_norm(grad, grad_clip),var) if  np.unicode_.find(var.name,'output')==-1 else (grad,var) for grad,var in bptt_weight_grads_and_vars]\n",
    "        # apply gradients \n",
    "        bptt_weight_train_op = bptt_weight_optimizer.apply_gradients(bptt_cropped_weight_grads_and_vars)\n",
    "    \n",
    "    ##################\n",
    "    # SUMMARIES ######\n",
    "    ##################\n",
    "    \n",
    "    with tf.name_scope(\"bptt_weight_summaries\") as scope: \n",
    "        # bptt sensitivity tensor \n",
    "        tf.summary.histogram('bptt_kernel_grad',bptt_grad_cost_trainables[0]+1e-10)\n",
    "        tf.summary.histogram('bptt_kernel', bptt_grad_cost_trainables[0]+1e-10)\n",
    "                    # bptt output weight\n",
    "        tf.summary.histogram('bptt_output_weight_grad',bptt_grad_cost_trainables[1]+1e-10)\n",
    "        tf.summary.histogram('bptt_output_weights', bptt_grad_cost_trainables[1]+1e-10)\n",
    "                    # bptt loss and accuracy\n",
    "        tf.summary.scalar('bptt_loss_output_prediction',bptt_loss_output_prediction+1e-10)\n",
    "        \n",
    "        # bptt senstivity tensor and temporal filter \n",
    "        bptt_tensor_merged_summary_op=tf.summary.merge_all(scope=\"bptt_weight_summaries\")\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['variable: ', 'hidden_layer/rnn/conductance_spike_cell/kernel:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (102, 100)]\n",
      "['variable: ', 'output_layer/rnn/output_spike_cell/kernel:0']\n",
      "['variable: ', 0]\n",
      "['shape: ', (100, 1)]\n",
      "['variable: ', 'output_layer/rnn/output_spike_cell/bias:0']\n",
      "['variable: ', 0]\n",
      "['shape: ', (1,)]\n"
     ]
    }
   ],
   "source": [
    "# verify initializatio\n",
    "\n",
    "with tf.Session(graph=graph,) as sess : \n",
    "    sess.run(init)\n",
    "    values,trainable_vars = sess.run([variable_names,trainables])\n",
    "    for k, v in zip(variable_names,values):\n",
    "        print([\"variable: \" , k])\n",
    "        #print([\"value: \" , v])\n",
    "        print([\"variable: \" , np.unicode_.find(k,'output')]) \n",
    "        print([\"shape: \" , v.shape])\n",
    "        #print(v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.environ['HOME']+\"/MyData/KeRNL/logs/bptt_snn_addition/add_eta_weight_%1.0e_batch_%1.0e_hum_hidd_%1.0e_gc_%1.0e_steps_%1.0e_run_%s\" %(weight_learning_rate,batch_size,num_hidden,grad_clip,training_steps, datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "filelist = [ f for f in os.listdir(log_dir) if f.endswith(\".local\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(log_dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2, bptt weight loss 397.244\n",
      "Step: 51, bptt weight loss 354.662\n",
      "Step: 101, bptt weight loss 347.002\n",
      "Step: 151, bptt weight loss 430.255\n",
      "Step: 201, bptt weight loss 288.001\n",
      "Step: 251, bptt weight loss 356.837\n",
      "Step: 301, bptt weight loss 305.316\n",
      "Step: 351, bptt weight loss 348.729\n",
      "Step: 401, bptt weight loss 245.598\n",
      "Step: 451, bptt weight loss 287.464\n",
      "Step: 501, bptt weight loss 246.126\n",
      "Step: 551, bptt weight loss 240.125\n",
      "Step: 601, bptt weight loss 222.274\n",
      "Step: 651, bptt weight loss 193.074\n",
      "Step: 701, bptt weight loss 196.821\n",
      "Step: 751, bptt weight loss 197.269\n",
      "Step: 801, bptt weight loss 190.732\n",
      "Step: 851, bptt weight loss 184.934\n",
      "Step: 901, bptt weight loss 196.524\n",
      "Step: 951, bptt weight loss 133.992\n",
      "Step: 1001, bptt weight loss 137.271\n",
      "Step: 1051, bptt weight loss 205.615\n",
      "Step: 1101, bptt weight loss 112.918\n",
      "Step: 1151, bptt weight loss 106.671\n",
      "Step: 1201, bptt weight loss 150.113\n",
      "Step: 1251, bptt weight loss 147.707\n",
      "Step: 1301, bptt weight loss 129.931\n",
      "Step: 1351, bptt weight loss 110.754\n",
      "Step: 1401, bptt weight loss 61.508\n",
      "Step: 1451, bptt weight loss 57.553\n",
      "Step: 1501, bptt weight loss 100.198\n",
      "Step: 1551, bptt weight loss 104.332\n",
      "Step: 1601, bptt weight loss 72.315\n",
      "Step: 1651, bptt weight loss 87.070\n",
      "Step: 1701, bptt weight loss 54.052\n",
      "Step: 1751, bptt weight loss 63.039\n",
      "Step: 1801, bptt weight loss 70.782\n",
      "Step: 1851, bptt weight loss 49.922\n",
      "Step: 1901, bptt weight loss 48.530\n",
      "Step: 1951, bptt weight loss 60.617\n",
      "Step: 2001, bptt weight loss 54.577\n",
      "Step: 2051, bptt weight loss 57.788\n",
      "Step: 2101, bptt weight loss 44.573\n",
      "Step: 2151, bptt weight loss 41.593\n",
      "Step: 2201, bptt weight loss 44.498\n",
      "Step: 2251, bptt weight loss 42.914\n",
      "Step: 2301, bptt weight loss 49.477\n",
      "Step: 2351, bptt weight loss 53.314\n",
      "Step: 2401, bptt weight loss 31.215\n",
      "Step: 2451, bptt weight loss 24.778\n",
      "Step: 2501, bptt weight loss 47.289\n",
      "Step: 2551, bptt weight loss 31.924\n",
      "Step: 2601, bptt weight loss 29.557\n",
      "Step: 2651, bptt weight loss 39.746\n",
      "Step: 2701, bptt weight loss 24.413\n",
      "Step: 2751, bptt weight loss 16.227\n",
      "Step: 2801, bptt weight loss 38.775\n",
      "Step: 2851, bptt weight loss 41.329\n",
      "Step: 2901, bptt weight loss 32.292\n",
      "Step: 2951, bptt weight loss 41.421\n",
      "Step: 3001, bptt weight loss 54.346\n",
      "Step: 3051, bptt weight loss 36.325\n",
      "Step: 3101, bptt weight loss 38.029\n",
      "Step: 3151, bptt weight loss 30.541\n",
      "Step: 3201, bptt weight loss 32.292\n",
      "Step: 3251, bptt weight loss 21.826\n",
      "Step: 3301, bptt weight loss 18.194\n",
      "Step: 3351, bptt weight loss 42.717\n",
      "Step: 3401, bptt weight loss 40.898\n",
      "Step: 3451, bptt weight loss 41.796\n",
      "Step: 3501, bptt weight loss 37.497\n",
      "Step: 3551, bptt weight loss 48.330\n",
      "Step: 3601, bptt weight loss 33.403\n",
      "Step: 3651, bptt weight loss 39.377\n",
      "Step: 3701, bptt weight loss 29.619\n",
      "Step: 3751, bptt weight loss 37.018\n",
      "Step: 3801, bptt weight loss 70.147\n",
      "Step: 3851, bptt weight loss 27.170\n",
      "Step: 3901, bptt weight loss 23.625\n",
      "Step: 3951, bptt weight loss 41.312\n",
      "Step: 4001, bptt weight loss 46.557\n",
      "Step: 4051, bptt weight loss 26.865\n",
      "Step: 4101, bptt weight loss 28.776\n",
      "Step: 4151, bptt weight loss 37.245\n",
      "Step: 4201, bptt weight loss 42.931\n",
      "Step: 4251, bptt weight loss 35.148\n",
      "Step: 4301, bptt weight loss 25.634\n",
      "Step: 4351, bptt weight loss 39.318\n",
      "Step: 4401, bptt weight loss 14.892\n",
      "Step: 4451, bptt weight loss 27.340\n",
      "Step: 4501, bptt weight loss 40.992\n",
      "Step: 4551, bptt weight loss 23.110\n",
      "Step: 4601, bptt weight loss 17.985\n",
      "Step: 4651, bptt weight loss 19.441\n",
      "Step: 4701, bptt weight loss 48.825\n",
      "Step: 4751, bptt weight loss 29.569\n",
      "Step: 4801, bptt weight loss 39.602\n",
      "Step: 4851, bptt weight loss 24.978\n",
      "Step: 4901, bptt weight loss 15.658\n",
      "Step: 4951, bptt weight loss 31.671\n",
      "Step: 5001, bptt weight loss 29.912\n",
      "Optimization Finished!\n",
      "Model saved in path: /home/eghbal/MyData/KeRNL/logs/bptt_snn_addition/add_eta_weight_1e-05_batch_2e+01_hum_hidd_1e+02_gc_2e+02_steps_5e+03_run_20190226_1421/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "# write graph into tensorboard \n",
    "tb_writer = tf.summary.FileWriter(log_dir,graph)\n",
    "# run a training session \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1,training_steps+1):\n",
    "        batch_x, batch_y = adding_problem.get_batch(batch_size=batch_size,time_steps=time_steps)\n",
    "        bptt_weight_train, bptt_loss=sess.run([bptt_weight_train_op,bptt_loss_output_prediction],feed_dict={X:batch_x, Y:batch_y})\n",
    "        # run summaries \n",
    "        bptt_tensor_merged_summary=sess.run(bptt_tensor_merged_summary_op,feed_dict={X:batch_x, Y:batch_y})\n",
    "        \n",
    "        tb_writer.add_summary(bptt_tensor_merged_summary, global_step=step)\n",
    "        # \n",
    "        if step % display_step==0 or step==1 : \n",
    "            # get batch loss and accuracy \n",
    "            print('Step: {}, bptt weight loss {:.3f}'.format(step + 1, bptt_loss))\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    #test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "    #test_label = mnist.test.labels[:test_len]\n",
    "    #print(\"Testing Accuracy:\", \n",
    "    #    sess.run(loss_output_prediction, feed_dict={X: test_data, Y: test_label}))\n",
    "    save_path = saver.save(sess, log_dir+\"/model.ckpt\", global_step=step,write_meta_graph=True)\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
