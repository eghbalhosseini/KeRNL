{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes about the implementation \n",
    "-  both input and recurrent weight are combined into 1 kernel matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import hashlib\n",
    "import numbers\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import kernl_spiking_cell_v4 as kernl_spiking_cell\n",
    "import adding_problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "# Training Parameters\n",
    "tensor_learning_rate = 1e-6\n",
    "weight_learning_rate = 1e-3\n",
    "training_steps = 4000\n",
    "buffer_size=700\n",
    "batch_size = 25\n",
    "training_size=batch_size*training_steps\n",
    "epochs=100\n",
    "test_size=10000\n",
    "display_step = 200\n",
    "grad_clip=100\n",
    "# Network Parameters\n",
    "# adding problem data input (first input are the random digits , second input is the mask)\n",
    "time_steps = 100\n",
    "num_hidden = 100 # hidden layer num of features\n",
    "num_output = 1 # value of the addition estimation\n",
    "#\n",
    "num_input=2\n",
    "num_units_input_layer=50\n",
    "num_context_unit=1\n",
    "# Noise Parameters\n",
    "perturbation_std=1e-10\n",
    "training_x, training_y = adding_problem.get_batch(batch_size=training_size,time_steps=time_steps)\n",
    "savepath='~/Desktop/openmind/logs/kernl_rnn_addition_dataset/kernl_rnn_tanh_add_T_2e+02_tanh_add_eta_W_1e-03_eta_T_1e-05_Noise_1e-10_batch_2e+01_hum_hidd_1e+02_gc_1e+02_steps_4e+03_run_20190308_1804'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensor(\"input_layer/rnn/while/rnn/input_spike_cell/strided_slice:0\", shape=(), dtype=int32): Please use float \n",
      "WARNING:tensorflow:(?, 50): Please use float \n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The passed save_path is not a valid checkpoint: /home/eghbal/Desktop/openmind/logs/kernl_snn_addition_dataset/kernl_snn_add_eta_weight_1e-03_batch_2e+01_hum_hidd_1e+02_gc_1e+02_steps_4e+03_run_20190309_0213/model.ckpt-4000000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8a3b9b1bd180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnew_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'model.ckpt-400000.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnew_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'model.ckpt-4000000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_y\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \"\n\u001b[0;32m-> 1538\u001b[0;31m                        + compat.as_text(save_path))\n\u001b[0m\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: /home/eghbal/Desktop/openmind/logs/kernl_snn_addition_dataset/kernl_snn_add_eta_weight_1e-03_batch_2e+01_hum_hidd_1e+02_gc_1e+02_steps_4e+03_run_20190309_0213/model.ckpt-4000000"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    new_saver = tf.train.import_meta_graph(savepath+'model.ckpt-400000.meta')\n",
    "    new_saver.restore(sess, savepath+'model.ckpt-4000000')\n",
    "    sess.run(iter.initializer,feed_dict={X: training_x, Y: training_y , BATCH_SIZE: batch_size})\n",
    "    outputs,hiddens=sess.run([kernl_output,kernl_hidden_states])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voltages=outputs[9,:,:]\n",
    "hidden_spikes=hiddens[9,:,:]\n",
    "input_spikes=inputs[9,:,:]\n",
    "plt.figure(figsize=[15,20])\n",
    "\n",
    "#ax1=plt.subplot(311)\n",
    "#colors_map=cm.viridis(np.linspace(0,1,voltages.shape[1]))\n",
    "#for t in range(num_classes):\n",
    "#    ax1.plot(voltages[:,t],color=colors_map[t,:])\n",
    "#    plt.xlim([0,timesteps])\n",
    "\n",
    "ax1=plt.subplot(411)\n",
    "plt.imshow(np.transpose(batch_x_full[9]))\n",
    "ax1.set_aspect(50)\n",
    "plt.ylabel('input pattern')\n",
    "ax2=plt.subplot(412)\n",
    "colors_map=cm.viridis(np.linspace(0,1,num_unit_input_layer+num_context_unit))\n",
    "for t in range(timesteps):\n",
    "    cross=np.argwhere(input_spikes[t,:])\n",
    "    ax2.scatter(cross*0+t,cross,color=colors_map[cross.flatten(),:],s=2)\n",
    "    plt.xlim([0,timesteps])\n",
    "plt.ylabel('input spikes')\n",
    "  \n",
    "ax3=plt.subplot(413)\n",
    "colors_map=cm.viridis(np.linspace(0,1,num_hidden))\n",
    "for t in range(timesteps):\n",
    "    cross=np.argwhere(hidden_spikes[t,:])\n",
    "    ax3.scatter(cross*0+t,cross,color=colors_map[cross.flatten(),:],s=2)\n",
    "    plt.xlim([0,timesteps])\n",
    "plt.ylabel('hidden layer spikes')\n",
    "ax1=plt.subplot(414)\n",
    "ax1.imshow(np.transpose(voltages))\n",
    "ax1.set_aspect(20)\n",
    "plt.ylabel('output class')\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(batch_x[9].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
