{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for implementing MNIST learning on kernel_SNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n",
    "This code implements a spiking neural net with conductance in input. the following equations govern the dynamic of the network. \n",
    "### transmembrane voltage dynamics\n",
    "first we model the transmembrane voltage as \n",
    "$$\\tau_m \\frac{dV_i}{dt}= - V_i(t)+ R_m \\times I^{syn}_i(t) $$ \n",
    "$$ {\\tau_a}_i \\frac{dB_i(t)}{dt} = b_i^0 -B_i(t)$$ \n",
    "where, $R_m$ is membrane resistance, $\\tau_m$ is membrane time constant, and ${\\tau_a}_i$ is adaptation time constant  .\n",
    "the synaptic current relates to synaptic activations in the following way\n",
    "$$I^{syn}_i(t)= \\sum_j W^{in}_{ij} \\times X(t) + \\sum_j W^{rec}_{ij} \\times S_j(t) $$ \n",
    "\n",
    "### neuron firing dynamics \n",
    "The firing dynamics of the neuron is model as a simple reseting. More specifically, \n",
    "$$V_i \\rightarrow V_{reset} \\ \\ \\  if \\ \\ \\ V_i>=B_{i} $$\n",
    "\n",
    "$ V_{\\Theta}$ represent the threshold voltage and $V_{reset}$ is the reset voltage of the neuron.\n",
    "\n",
    "### Input dynamics \n",
    "Input synapes are the the site of learning in the spiking network. Below a conductance based formulation is presented. \n",
    "First, the time-dependent input conductance to membrane is calculated as follows \n",
    "$$ g_i(t) = \\sum_j W_{ij} S_{j}(t) $$\n",
    "\n",
    "in the current version $S_{j}(t)$ is equal to spike at timestep $t$ without any decay dynamics. \n",
    "-  TODO the term $j$ reperesent all the neurons that have a synapse onto the neuron $i$. the time dependence of conductance is due to $S(t)$ which represent the spiking activity for neurons connected to neuron $i$ . The spiking activity has the following governing equations \n",
    "$$ S_{j} \\rightarrow S_{j}+1 \\quad if \\ neuron\\ j\\ fires$$\n",
    "$$ \\frac{dS_{j}(t)}{dt} = \\frac{-S_{j}(t)}{\\tau_s}$$ \n",
    "\n",
    "### Spike Adaptation dynamics \n",
    "The threshold for spiking increases with every spike emited from a neuron with the following dynamics \n",
    "$$ B_{i}(t) \\rightarrow B_{i}(t)+\\frac{\\beta}{{\\tau_a}_i} \\quad if \\ neuron\\ i\\ fires$$\n",
    "\n",
    "\n",
    "### implementation in discrete time \n",
    "we start with Euler method for modeling the dynamics \n",
    "### References \n",
    "-  Fiete, Ila R., Walter Senn, Claude Z. H. Wang, and Richard H. R. Hahnloser. 2010. “Spike-Time-Dependent Plasticity and Heterosynaptic Competition Organize Networks to Produce Long Scale-Free Sequences of Neural Activity.” Neuron 65 (4): 563–76. \n",
    "\n",
    "-  Bellec, Guillaume, Darjan Salaj, Anand Subramoney, Robert Legenstein, and Wolfgang Maass. 2018. “Long Short-Term Memory and Learning-to-Learn in Networks of Spiking Neurons.” arXiv [cs.NE]. arXiv. http://arxiv.org/abs/1803.09574.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import collections\n",
    "import hashlib\n",
    "import numbers\n",
    "import matplotlib.cm as cm\n",
    "from sys import getsizeof\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "import re\n",
    "\n",
    "# tensorflow and its dependencies \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.layers import base as base_layer\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import partitioned_variables\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import variables as tf_variables\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell import _Linear\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "## user defined modules \n",
    "# kernel rnn cell \n",
    "import kernl_spiking_cell_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# uplading mnist data \n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "tf.logging.set_verbosity(old_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial parameters for the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 2200\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "weight_learning_rate = 1e-5\n",
    "tensor_learning_rate=1e-3 \n",
    "training_steps = 5000\n",
    "batch_size = 25\n",
    "display_step = 25\n",
    "test_len=128\n",
    "grad_clip=200\n",
    "# Network Parameters\n",
    "# 1-input layer \n",
    "num_input = 1 # MNIST data input (img shape: 28*28)\n",
    "num_context_input=1\n",
    "MNIST_timesteps = 28*28 # timesteps\n",
    "context_timesteps=54\n",
    "timesteps=MNIST_timesteps+context_timesteps\n",
    "num_unit_input_layer=80 # input layer neurons\n",
    "num_context_unit=1\n",
    "noise_std=0.5\n",
    "# 2-hidden layer \n",
    "num_hidden = 200 # hidden layer num of features\n",
    "# 3-output layer \n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# report batch number \n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "print(\"Total number of batches:\", total_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernl_SNN_all_states(x,context):\n",
    "    with tf.variable_scope('context_layer') as scope:\n",
    "        context_input_layer_cell=kernl_spiking_cell_v3.context_input_spike_cell(num_units=1,context_switch=MNIST_timesteps)\n",
    "        context_initial_state = context_input_layer_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        output_context, states_context = tf.nn.dynamic_rnn(context_input_layer_cell, dtype=tf.float32, inputs=context,initial_state=context_initial_state)\n",
    "        \n",
    "    with tf.variable_scope('input_layer') as scope: \n",
    "        input_layer_cell=kernl_spiking_cell_v3.input_spike_cell(num_units=num_unit_input_layer)\n",
    "        input_initial_state = input_layer_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        output_l1, states_l1 = tf.nn.dynamic_rnn(input_layer_cell, dtype=tf.float32, inputs=x,initial_state=input_initial_state)\n",
    "        \n",
    "    with tf.variable_scope('hidden_layer') as scope: \n",
    "        hidden_layer_cell=kernl_spiking_cell_v3.kernl_spike_Cell(num_units=num_hidden,\n",
    "                                                                 num_inputs=num_unit_input_layer+num_context_unit,\n",
    "                                                                 time_steps=timesteps,\n",
    "                                                                 output_is_tuple=True,\n",
    "                                                                 tau_refract=1.0,\n",
    "                                                                 tau_m=20,\n",
    "                                                                 noise_std=noise_std)\n",
    "        hidden_initial_state = hidden_layer_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        output_hidden, states_hidden = tf.nn.dynamic_rnn(hidden_layer_cell, dtype=tf.float32, inputs=tf.concat([output_l1,output_context],-1),initial_state=hidden_initial_state)\n",
    "    with tf.variable_scope('output_layer') as scope : \n",
    "        output_layer_cell=kernl_spiking_cell_v3.output_spike_cell(num_units=num_classes)\n",
    "        output_voltage, voltage_states=tf.nn.dynamic_rnn(output_layer_cell,dtype=tf.float32,inputs=output_hidden.spike)\n",
    "\n",
    "    return output_voltage,output_hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient equation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we derive the governing equations for calculating gradients, sensitivity tensor, and temporal filter. We first rewrite the equation for the cell for mathematical simplicitiy. We can rewrite the governing diffrential equation for the network in discrete time as follows <br>\n",
    "$$V_{t+1}=\\sigma_{threshold}(\\delta \\times V_{t} + R_m \\times W^{in} \\times X_{t}+ R_m \\times W^{rec} \\times S_{t})$$ <br>\n",
    "$$S_{t+1}= \\rho \\times S_t + \\sigma_{spike}(V_t)$$ <br>\n",
    "$$Y^{spike}_t=\\sigma_{spike}(V_t)$$  <br>\n",
    "<font color='red'> there is a problem with units in the equation above, look into it. </font> <br>\n",
    "considering a cost function that depends on the $Y^{spike}_t$ and $X_t$ such as $C=C(X(-),f(Y^{spike}(-)),Y^{target})$ where $f(Y^{spike}(-))$ is the output transformation from hidden layer to output layer, in this case a linear layer of neurons. we need to calculate $\\frac{dC}{dW}$ for $W^{rec}$ and $W^{in}$. considering that output is determined by $V_t$ we make the following assertion. \n",
    "$$\\frac{\\partial C}{\\partial S} = 0 $$ \n",
    "\n",
    "in addition following the chain rule for computing $\\frac{\\partial C}{\\partial W}$ we have  <br>\n",
    "$$\\frac{\\partial C}{\\partial W^{rec}} = \\frac{\\partial C}{\\partial Y^{spike}} \\times \\frac{\\partial Y^{spike}}{\\partial V} \\times \\frac{\\partial V}{\\partial W^{rec}}$$ <br> \n",
    "$$\\frac{\\partial C}{\\partial W^{in}} = \\frac{\\partial C}{\\partial Y^{spike}} \\times \\frac{\\partial Y^{spike}}{\\partial V} \\times \\frac{\\partial V}{\\partial W^{in}}$$ <br>\n",
    "\n",
    "we start by implementing the sensitivity lemma, and rewrite the equation for gradients \n",
    "$$g_i(t)=\\sum_jW_{ij}S_j(t)$$ <br>\n",
    "$$\\frac{dC}{dW_{ij}}=\\frac{1}{T} \\int_0^T dt \\frac{\\delta C}{\\delta W_{ij}(t)}=\\frac{1}{T} \\int_0^T dt \\frac{\\delta C}{\\delta g_{i}(t)}\\times S_j(t)$$  <br>\n",
    "$$ \\frac{\\delta C}{\\delta g_{i}(t)}= \\sum_k \\int_0^T \\frac{\\delta C}{\\delta y^{spike}_{k}(t')} \\times \\frac{\\delta y^{spike}_{k}(t') }{\\delta v_{k}(t')} \\times \\frac{\\delta v_k(t')}{\\delta g_i(t)}$$ \n",
    "<br>\n",
    "first we focus on the first two terms in the equation, we can caluculate $\\frac{\\delta C}{\\delta y^{spike}_{k}(t')}$ as error in output $k$ at time $t'$. In addition $\\frac{\\delta y^{spike}_{k}(t') }{\\delta v_{k}(t')}$ is equivalent to $ \\sigma'_{spike}$ . in order to avoid discontinuitiy in $\\sigma'_{spike}$ we use a pseudo derivative defined as \n",
    "$$ \\frac{\\delta y^{spike}_k(t)}{\\delta v_{k}(t)} := max\\{0,1-|v^{norm}{k}(t)|\\}$$\n",
    "$$ v^{norm}{k}(t) = \\frac{v_k(t)-B_{k}(t)}{B_{k}(t)} $$\n",
    "<br>\n",
    "in the equation above the term that depends on interactions between units is  $ \\frac{\\delta v_k(t')}{\\delta g_i(t)} $ and captures how activity of neuron $i$ at time $t$ affects the activity of neuron $k$ at time $t'$ . In order to estimate this interaction we make the following assumption <br>\n",
    "\n",
    "$$\\frac{\\delta v_k(t')}{\\delta g_i(t)} = m_{ki}(t,t') = M_{ki}\\times K(t-t') \\times h(s_i(t))$$  \n",
    "<font color='red'> how one can learn h and M and K emprically, or what other forms are good estimates of the following interaction. </font> <br>\n",
    "\n",
    "going back to the gradient definition we can incorporate the derivation of interaction and and calculate the gradient as follows\n",
    "<br>\n",
    "$$\\frac{dC}{dW_{ij}}=\\frac{1}{T} \\int_0^T dt \\frac{\\delta C}{\\delta W_{ij}(t)}=\\frac{1}{T} \\int_0^T dt \\frac{\\delta C}{\\delta g_{i}(t)}\\times S_j(t)$$ <br>\n",
    "$$\\frac{dC}{dW_{ij}}=\\frac{1}{T} \\int_0^T dt \\frac{\\delta C}{\\delta W_{ij}(t)}=\\frac{1}{T} \\int_0^T dt \\frac{\\delta C}{\\delta y^{spike}_{k}(t')} \\times  M_{ki}\\times K(t-t') \\times h\\big(S_i(t)\\big) \\times S_j(t)$$\n",
    "<br>\n",
    "### learning of $M$ and $K(\\tau)$\n",
    "\n",
    "first we focus on estimating the two parameters $M_{ki}$ and $K(t)$ . We first apply a small iid hidden perturbation $\\xi$ to $S(t)$ and track its effect on the output voltage.\n",
    "<br>\n",
    "$$\\tilde{V}_{t+1}=\\sigma_{threshold}(\\delta \\times \\tilde{V}_{t} + R_m \\times W^{in} \\times X_{t}+ R_m \\times W^{rec} \\times \\big(S_{t}+\\xi_t)\\big)$$ <br>\n",
    "we then minimize the following cost function <br>\n",
    "$$ C_{M,K}= \\Big(\\tilde{V_i}(t)-V_i(t)-\\sum_j M_{ij} \\sum_{\\tau}K(\\tau)\\times\\xi_j(t-\\tau)\\Big)^2$$\n",
    "<br>\n",
    "for a single exponential filter $K(\\tau)=exp(-\\gamma_j\\tau)$ we have  <br>\n",
    "\n",
    "$$ C_{M,K}= \\Big(\\tilde{V_i}(t)-V_i(t)-\\sum_j M_{ij} \\sum_{\\tau} exp(-\\gamma_j\\tau) \\times \\xi_j(t-\\tau)\\Big)^2$$\n",
    "\n",
    "<font color='red'> add pseudo code here for the spiking neuron cell. </font> <br>\n",
    "### Pseudo-code for kernl_snn_cell\n",
    "kernel_snn_v_2.1 <br>\n",
    "while t<T do: <br>\n",
    ">             update I_syn = W_in*X + W_rec*S <br>\n",
    "              find neurons outside refractory period : eligible <br>\n",
    "              calculate decay factor for v_mem : alpha <br>\n",
    "              update v_mem for eligible neurons :  v_t+1= alpha* v_t + (1-alpha)* I_syn <br> \n",
    "              find spike_t+1 <-- v_mem > Beta <br>\n",
    "              v_reset <-- v_mem for neurons crossing threshold (emmited spikes)\n",
    "              update threshold <br>\n",
    "              update refractory period <br>\n",
    "              update synaptic input <br>\n",
    "              update eligibility trace <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation graph for learning $M$ and $K(\\tau)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    # check hardware \n",
    "    \n",
    "    # define weights and inputs to the network\n",
    "    X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "    Context=tf.placeholder('float',shape=[batch_size,timesteps,num_context_input])\n",
    "    # define a function for extraction of variable names\n",
    "    kernl_output,kernl_hidden_states=kernl_SNN_all_states(X,Context)\n",
    "    \n",
    "    trainables=tf.trainable_variables()\n",
    "    variable_names=[v.name for v in tf.trainable_variables()]\n",
    "    # \n",
    "    find_joing_index = lambda x, name_1,name_2 : [a and b for a,b in zip([np.unicode_.find(k.name, name_1)>-1 for k in x] ,[np.unicode_.find(k.name, name_2)>-1 for k in x])].index(True)\n",
    "    # find trainable parameters for kernl \n",
    "    with tf.name_scope('kernl_Trainables') as scope:\n",
    "        kernl_output_weight_index= find_joing_index(trainables,'output_layer','kernel')\n",
    "        kernl_temporal_filter_index= find_joing_index(trainables,'kernl','temporal_filter')\n",
    "        kernl_sensitivity_tensor_index= find_joing_index(trainables,'kernl','sensitivity_tensor')\n",
    "        kernl_kernel_index= find_joing_index(trainables,'hidden_layer','kernel')\n",
    "    # \n",
    "        kernl_tensor_training_indices=np.asarray([kernl_sensitivity_tensor_index,kernl_temporal_filter_index],dtype=np.int)\n",
    "        kernl_tensor_trainables= [trainables[k] for k in kernl_tensor_training_indices]\n",
    "    #\n",
    "        kernl_weight_training_indices=np.asarray([kernl_kernel_index,kernl_output_weight_index],dtype=np.int)\n",
    "        kernl_weight_trainables= [trainables[k] for k in kernl_weight_training_indices]\n",
    "    \n",
    " \n",
    "    ##################\n",
    "    # kernl train ####\n",
    "    ##################\n",
    "    with tf.name_scope(\"kernl_performance\") as scope:\n",
    "        # outputs \n",
    "        kernl_logit=tf.reduce_mean(kernl_output[:,-context_timesteps:,:],axis=1)\n",
    "        kernl_loss_output_prediction=tf.losses.softmax_cross_entropy(onehot_labels=Y,logits=kernl_logit)\n",
    "        kernl_prediction = tf.nn.softmax(kernl_logit)\n",
    "        kernl_correct_pred = tf.equal(tf.argmax(kernl_prediction, 1), tf.argmax(Y, 1))\n",
    "        kernl_accuracy = tf.reduce_mean(tf.cast(kernl_correct_pred, tf.float32))\n",
    "        \n",
    "    with tf.name_scope('kernl_train_tensors') as scope: \n",
    "        kernl_loss_state_prediction=tf.losses.mean_squared_error(tf.subtract(kernl_hidden_states.v_mem_hat[:,-1,:], kernl_hidden_states.v_mem[:,-1,:]),tf.matmul(kernl_hidden_states.Theta[:,-1,:],trainables[kernl_sensitivity_tensor_index]))\n",
    "        kernl_tensor_optimizer = tf.train.RMSPropOptimizer(learning_rate=tensor_learning_rate)\n",
    "        kernl_tensor_grads=tf.gradients(ys=kernl_loss_state_prediction,xs=kernl_tensor_trainables)\n",
    "        kernl_tensor_grad_and_vars=list(zip(kernl_tensor_grads,kernl_tensor_trainables))\n",
    "        kernl_tensor_train_op=kernl_tensor_optimizer.apply_gradients(kernl_tensor_grad_and_vars)\n",
    "        \n",
    "    \n",
    "    ##################\n",
    "    # SUMMARIES ######\n",
    "    ##################\n",
    "    \n",
    "    with tf.name_scope(\"kernl_tensor_summaries\") as scope: \n",
    "        # kernl sensitivity tensor \n",
    "        tf.summary.histogram('kernl_sensitivity_tensor_grad',kernl_tensor_grads[0]+1e-10)\n",
    "        tf.summary.histogram('kernl_sensitivity_tensor',trainables[kernl_sensitivity_tensor_index]+1e-10)\n",
    "        # kernl temporal filter \n",
    "        tf.summary.histogram('kernl_temporal_filter_grad',kernl_tensor_grads[1]+1e-10)\n",
    "        tf.summary.histogram('kernl_temporal_filter',trainables[kernl_temporal_filter_index]+1e-10)\n",
    "        # kernl loss \n",
    "        tf.summary.scalar('kernl_loss_state_prediction',kernl_loss_state_prediction+1e-10)\n",
    "        # kernl senstivity tensor and temporal filter \n",
    "        tf.summary.image('kernl_sensitivity_tensor',tf.expand_dims(tf.expand_dims(trainables[kernl_sensitivity_tensor_index],axis=0),axis=-1))\n",
    "        tf.summary.image('kernl_sensitivity_tensor_grad',tf.expand_dims(tf.expand_dims(kernl_tensor_grads[0],axis=0),axis=-1))\n",
    "        tf.summary.image('kernl_temporal_filter',tf.expand_dims(tf.expand_dims(tf.expand_dims(trainables[kernl_temporal_filter_index],axis=0),axis=-1),axis=-1))\n",
    "        tf.summary.image('kernl_temporal_filter_grad',tf.expand_dims(tf.expand_dims(tf.expand_dims(kernl_tensor_grads[1],axis=0),axis=-1),axis=-1))\n",
    "        kernl_tensor_merged_summary_op=tf.summary.merge_all(scope=\"kernl_tensor_summaries\")\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['variable: ', 'hidden_layer/rnn/kernl_spike__cell/temporal_filter:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (200,)]\n",
      "['variable: ', 'hidden_layer/rnn/kernl_spike__cell/sensitivity_tensor:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (200, 200)]\n",
      "['variable: ', 'hidden_layer/rnn/kernl_spike__cell/kernel:0']\n",
      "['variable: ', -1]\n",
      "['shape: ', (281, 200)]\n",
      "['variable: ', 'output_layer/rnn/output_spike_cell/kernel:0']\n",
      "['variable: ', 0]\n",
      "['shape: ', (200, 10)]\n"
     ]
    }
   ],
   "source": [
    "# verify initializatio\n",
    "\n",
    "with tf.Session(graph=graph,) as sess : \n",
    "    sess.run(init)\n",
    "    values,trainable_vars = sess.run([variable_names,trainables])\n",
    "    for k, v in zip(variable_names,values):\n",
    "        print([\"variable: \" , k])\n",
    "        #print([\"value: \" , v])\n",
    "        print([\"variable: \" , np.unicode_.find(k,'output')]) \n",
    "        print([\"shape: \" , v.shape])\n",
    "        #print(v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/home/eghbal/MyData/KeRNL/logs/kernl_SNN_v3/MNIST_gc_%d_eta_m_%d_eta_%d_batch_%d_run_%s\" %(grad_clip,tensor_learning_rate,weight_learning_rate,batch_size, datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "filelist = [ f for f in os.listdir(log_dir) if f.endswith(\".local\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(log_dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2, keRNL tensor Loss 8360.558,\n",
      "Step: 26, keRNL tensor Loss 8391.920,\n",
      "Step: 51, keRNL tensor Loss 8725.039,\n",
      "Step: 76, keRNL tensor Loss 7907.877,\n",
      "Step: 101, keRNL tensor Loss 7679.605,\n",
      "Step: 126, keRNL tensor Loss 8445.836,\n",
      "Step: 151, keRNL tensor Loss 8075.896,\n",
      "Step: 176, keRNL tensor Loss 7681.286,\n",
      "Step: 201, keRNL tensor Loss 7864.392,\n",
      "Step: 226, keRNL tensor Loss 8248.395,\n",
      "Step: 251, keRNL tensor Loss 7604.929,\n",
      "Step: 276, keRNL tensor Loss 7745.477,\n",
      "Step: 301, keRNL tensor Loss 7417.432,\n",
      "Step: 326, keRNL tensor Loss 7870.850,\n",
      "Step: 351, keRNL tensor Loss 7877.712,\n",
      "Step: 376, keRNL tensor Loss 7769.990,\n",
      "Step: 401, keRNL tensor Loss 7137.896,\n",
      "Step: 426, keRNL tensor Loss 7758.786,\n",
      "Step: 451, keRNL tensor Loss 7499.935,\n",
      "Step: 476, keRNL tensor Loss 7462.279,\n",
      "Step: 501, keRNL tensor Loss 7260.229,\n",
      "Step: 526, keRNL tensor Loss 7388.560,\n",
      "Step: 551, keRNL tensor Loss 7208.475,\n",
      "Step: 576, keRNL tensor Loss 7633.149,\n",
      "Step: 601, keRNL tensor Loss 7532.893,\n",
      "Step: 626, keRNL tensor Loss 7354.835,\n",
      "Step: 651, keRNL tensor Loss 7290.299,\n",
      "Step: 676, keRNL tensor Loss 7285.706,\n",
      "Step: 701, keRNL tensor Loss 7402.926,\n",
      "Step: 726, keRNL tensor Loss 7446.643,\n",
      "Step: 751, keRNL tensor Loss 6754.641,\n",
      "Step: 776, keRNL tensor Loss 7272.633,\n",
      "Step: 801, keRNL tensor Loss 6943.883,\n",
      "Step: 826, keRNL tensor Loss 7460.713,\n",
      "Step: 851, keRNL tensor Loss 7235.765,\n",
      "Step: 876, keRNL tensor Loss 6336.753,\n",
      "Step: 901, keRNL tensor Loss 6830.268,\n",
      "Step: 926, keRNL tensor Loss 6945.770,\n",
      "Step: 951, keRNL tensor Loss 6694.268,\n",
      "Step: 976, keRNL tensor Loss 6940.122,\n",
      "Step: 1001, keRNL tensor Loss 7042.864,\n",
      "Step: 1026, keRNL tensor Loss 6774.954,\n",
      "Step: 1051, keRNL tensor Loss 6752.672,\n",
      "Step: 1076, keRNL tensor Loss 6655.390,\n",
      "Step: 1101, keRNL tensor Loss 6960.611,\n",
      "Step: 1126, keRNL tensor Loss 7228.146,\n",
      "Step: 1151, keRNL tensor Loss 6794.961,\n",
      "Step: 1176, keRNL tensor Loss 6386.642,\n",
      "Step: 1201, keRNL tensor Loss 6753.569,\n",
      "Step: 1226, keRNL tensor Loss 6575.467,\n",
      "Step: 1251, keRNL tensor Loss 6692.214,\n",
      "Step: 1276, keRNL tensor Loss 6369.333,\n",
      "Step: 1301, keRNL tensor Loss 6979.270,\n",
      "Step: 1326, keRNL tensor Loss 6691.370,\n",
      "Step: 1351, keRNL tensor Loss 6571.792,\n",
      "Step: 1376, keRNL tensor Loss 6527.595,\n",
      "Step: 1401, keRNL tensor Loss 6303.021,\n",
      "Step: 1426, keRNL tensor Loss 6531.628,\n",
      "Step: 1451, keRNL tensor Loss 6330.157,\n",
      "Step: 1476, keRNL tensor Loss 6583.277,\n",
      "Step: 1501, keRNL tensor Loss 6471.254,\n",
      "Step: 1526, keRNL tensor Loss 6378.490,\n",
      "Step: 1551, keRNL tensor Loss 6069.022,\n",
      "Step: 1576, keRNL tensor Loss 5773.841,\n",
      "Step: 1601, keRNL tensor Loss 6094.500,\n",
      "Step: 1626, keRNL tensor Loss 5817.296,\n",
      "Step: 1651, keRNL tensor Loss 6154.525,\n",
      "Step: 1676, keRNL tensor Loss 6433.753,\n",
      "Step: 1701, keRNL tensor Loss 5993.298,\n",
      "Step: 1726, keRNL tensor Loss 6015.354,\n",
      "Step: 1751, keRNL tensor Loss 6372.783,\n",
      "Step: 1776, keRNL tensor Loss 5966.096,\n",
      "Step: 1801, keRNL tensor Loss 6074.925,\n",
      "Step: 1826, keRNL tensor Loss 5942.656,\n",
      "Step: 1851, keRNL tensor Loss 5870.301,\n",
      "Step: 1876, keRNL tensor Loss 5935.875,\n",
      "Step: 1901, keRNL tensor Loss 5800.181,\n",
      "Step: 1926, keRNL tensor Loss 6080.137,\n",
      "Step: 1951, keRNL tensor Loss 5828.642,\n",
      "Step: 1976, keRNL tensor Loss 6077.308,\n",
      "Step: 2001, keRNL tensor Loss 5703.774,\n",
      "Step: 2026, keRNL tensor Loss 5753.596,\n",
      "Step: 2051, keRNL tensor Loss 5579.646,\n",
      "Step: 2076, keRNL tensor Loss 5504.314,\n",
      "Step: 2101, keRNL tensor Loss 5361.118,\n",
      "Step: 2126, keRNL tensor Loss 5365.441,\n",
      "Step: 2151, keRNL tensor Loss 5620.764,\n",
      "Step: 2176, keRNL tensor Loss 5571.025,\n",
      "Step: 2201, keRNL tensor Loss 5350.705,\n",
      "Step: 2226, keRNL tensor Loss 5524.356,\n",
      "Step: 2251, keRNL tensor Loss 5380.874,\n",
      "Step: 2276, keRNL tensor Loss 5503.631,\n",
      "Step: 2301, keRNL tensor Loss 5335.341,\n",
      "Step: 2326, keRNL tensor Loss 5479.493,\n",
      "Step: 2351, keRNL tensor Loss 5358.844,\n",
      "Step: 2376, keRNL tensor Loss 5327.118,\n",
      "Step: 2401, keRNL tensor Loss 5106.852,\n",
      "Step: 2426, keRNL tensor Loss 5468.464,\n",
      "Step: 2451, keRNL tensor Loss 5462.184,\n",
      "Step: 2476, keRNL tensor Loss 5152.058,\n",
      "Step: 2501, keRNL tensor Loss 5487.107,\n",
      "Step: 2526, keRNL tensor Loss 5286.741,\n",
      "Step: 2551, keRNL tensor Loss 5170.977,\n",
      "Step: 2576, keRNL tensor Loss 5025.532,\n",
      "Step: 2601, keRNL tensor Loss 5296.383,\n",
      "Step: 2626, keRNL tensor Loss 5186.926,\n",
      "Step: 2651, keRNL tensor Loss 4970.912,\n",
      "Step: 2676, keRNL tensor Loss 5109.644,\n",
      "Step: 2701, keRNL tensor Loss 5074.153,\n",
      "Step: 2726, keRNL tensor Loss 4818.581,\n",
      "Step: 2751, keRNL tensor Loss 4960.913,\n",
      "Step: 2776, keRNL tensor Loss 5126.286,\n",
      "Step: 2801, keRNL tensor Loss 5131.050,\n",
      "Step: 2826, keRNL tensor Loss 4866.315,\n",
      "Step: 2851, keRNL tensor Loss 4970.507,\n",
      "Step: 2876, keRNL tensor Loss 4681.413,\n",
      "Step: 2901, keRNL tensor Loss 4779.244,\n",
      "Step: 2926, keRNL tensor Loss 4844.872,\n",
      "Step: 2951, keRNL tensor Loss 5024.583,\n",
      "Step: 2976, keRNL tensor Loss 4879.368,\n",
      "Step: 3001, keRNL tensor Loss 4857.545,\n",
      "Step: 3026, keRNL tensor Loss 4717.406,\n",
      "Step: 3051, keRNL tensor Loss 4830.190,\n",
      "Step: 3076, keRNL tensor Loss 4493.282,\n",
      "Step: 3101, keRNL tensor Loss 4875.755,\n",
      "Step: 3126, keRNL tensor Loss 4812.563,\n",
      "Step: 3151, keRNL tensor Loss 4888.844,\n",
      "Step: 3176, keRNL tensor Loss 4736.066,\n",
      "Step: 3201, keRNL tensor Loss 4640.401,\n",
      "Step: 3226, keRNL tensor Loss 4478.493,\n",
      "Step: 3251, keRNL tensor Loss 4525.934,\n",
      "Step: 3276, keRNL tensor Loss 4671.729,\n",
      "Step: 3301, keRNL tensor Loss 4732.668,\n",
      "Step: 3326, keRNL tensor Loss 4739.172,\n",
      "Step: 3351, keRNL tensor Loss 4638.144,\n",
      "Step: 3376, keRNL tensor Loss 4968.785,\n",
      "Step: 3401, keRNL tensor Loss 4538.410,\n",
      "Step: 3426, keRNL tensor Loss 4321.738,\n",
      "Step: 3451, keRNL tensor Loss 4616.597,\n",
      "Step: 3476, keRNL tensor Loss 4315.985,\n",
      "Step: 3501, keRNL tensor Loss 4730.527,\n",
      "Step: 3526, keRNL tensor Loss 4088.127,\n",
      "Step: 3551, keRNL tensor Loss 4402.129,\n",
      "Step: 3576, keRNL tensor Loss 4438.921,\n",
      "Step: 3601, keRNL tensor Loss 4200.478,\n",
      "Step: 3626, keRNL tensor Loss 4393.803,\n",
      "Step: 3651, keRNL tensor Loss 4415.464,\n",
      "Step: 3676, keRNL tensor Loss 4333.103,\n",
      "Step: 3701, keRNL tensor Loss 4312.259,\n",
      "Step: 3726, keRNL tensor Loss 4116.069,\n",
      "Step: 3751, keRNL tensor Loss 4180.004,\n",
      "Step: 3776, keRNL tensor Loss 4334.626,\n",
      "Step: 3801, keRNL tensor Loss 4112.762,\n",
      "Step: 3826, keRNL tensor Loss 4374.032,\n",
      "Step: 3851, keRNL tensor Loss 4027.343,\n",
      "Step: 3876, keRNL tensor Loss 4085.265,\n",
      "Step: 3901, keRNL tensor Loss 4380.979,\n",
      "Step: 3926, keRNL tensor Loss 4091.334,\n",
      "Step: 3951, keRNL tensor Loss 4169.526,\n",
      "Step: 3976, keRNL tensor Loss 3950.612,\n",
      "Step: 4001, keRNL tensor Loss 4062.492,\n",
      "Step: 4026, keRNL tensor Loss 4089.072,\n",
      "Step: 4051, keRNL tensor Loss 4252.518,\n",
      "Step: 4076, keRNL tensor Loss 3983.788,\n",
      "Step: 4101, keRNL tensor Loss 3899.785,\n",
      "Step: 4126, keRNL tensor Loss 3864.491,\n",
      "Step: 4151, keRNL tensor Loss 3924.778,\n",
      "Step: 4176, keRNL tensor Loss 4042.350,\n",
      "Step: 4201, keRNL tensor Loss 4104.551,\n",
      "Step: 4226, keRNL tensor Loss 3849.822,\n",
      "Step: 4251, keRNL tensor Loss 4099.601,\n",
      "Step: 4276, keRNL tensor Loss 3840.558,\n",
      "Step: 4301, keRNL tensor Loss 4011.621,\n",
      "Step: 4326, keRNL tensor Loss 3760.065,\n",
      "Step: 4351, keRNL tensor Loss 3713.685,\n",
      "Step: 4376, keRNL tensor Loss 3728.312,\n",
      "Step: 4401, keRNL tensor Loss 3920.431,\n",
      "Step: 4426, keRNL tensor Loss 3644.786,\n",
      "Step: 4451, keRNL tensor Loss 3737.277,\n",
      "Step: 4476, keRNL tensor Loss 3849.712,\n",
      "Step: 4501, keRNL tensor Loss 3685.510,\n",
      "Step: 4526, keRNL tensor Loss 3585.209,\n",
      "Step: 4551, keRNL tensor Loss 3918.518,\n",
      "Step: 4576, keRNL tensor Loss 3747.321,\n",
      "Step: 4601, keRNL tensor Loss 3811.679,\n",
      "Step: 4626, keRNL tensor Loss 3708.978,\n",
      "Step: 4651, keRNL tensor Loss 3647.962,\n",
      "Step: 4676, keRNL tensor Loss 3650.243,\n",
      "Step: 4701, keRNL tensor Loss 3767.871,\n",
      "Step: 4726, keRNL tensor Loss 3856.575,\n",
      "Step: 4751, keRNL tensor Loss 3405.594,\n",
      "Step: 4776, keRNL tensor Loss 3507.305,\n",
      "Step: 4801, keRNL tensor Loss 3362.175,\n",
      "Step: 4826, keRNL tensor Loss 3579.446,\n",
      "Step: 4851, keRNL tensor Loss 3515.542,\n",
      "Step: 4876, keRNL tensor Loss 3559.600,\n",
      "Step: 4901, keRNL tensor Loss 3604.045,\n",
      "Step: 4926, keRNL tensor Loss 3509.501,\n",
      "Step: 4951, keRNL tensor Loss 3361.678,\n",
      "Step: 4976, keRNL tensor Loss 3715.379,\n",
      "Step: 5001, keRNL tensor Loss 3403.432,\n",
      "Optimization Finished!\n",
      "Model saved in path: /home/eghbal/MyData/KeRNL/logs/kernl_SNN_v3/MNIST_gc_200_eta_m_0_eta_0_batch_25_run_20190220_1559/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "# write graph into tensorboard \n",
    "tb_writer = tf.summary.FileWriter(log_dir,graph)\n",
    "# run a training session \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1,training_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x=batch_x.reshape((batch_size,MNIST_timesteps,num_input))\n",
    "        batch_x_full=np.concatenate([batch_x,np.zeros((batch_size,timesteps-MNIST_timesteps,num_input))],axis=1)\n",
    "        context_input=np.ones((batch_size,timesteps,num_context_input))\n",
    "        kernl_tensor_train,kernl_loss_state=sess.run([kernl_tensor_train_op,kernl_loss_state_prediction], feed_dict={X: batch_x_full,Y:batch_y,Context:context_input})\n",
    "        \n",
    "        # run summaries \n",
    "        kernl_tensor_merged_summary=sess.run(kernl_tensor_merged_summary_op,feed_dict={X:batch_x_full, Y:batch_y,Context:context_input})\n",
    "        \n",
    "        tb_writer.add_summary(kernl_tensor_merged_summary, global_step=step)\n",
    "        # \n",
    "        if step % display_step==0 or step==1 : \n",
    "            # get batch loss and accuracy \n",
    "            print('Step: {}, keRNL tensor Loss {:.3f},'.format(step + 1, kernl_loss_state))\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    #test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "    #test_label = mnist.test.labels[:test_len]\n",
    "    #print(\"Testing Accuracy:\", \n",
    "    #    sess.run(loss_output_prediction, feed_dict={X: test_data, Y: test_label}))\n",
    "    save_path = saver.save(sess, log_dir+\"/model.ckpt\", global_step=step,write_meta_graph=True)\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify initialization\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph,) as sess : \n",
    "    sess.run(init)\n",
    "    values,trainable_vars = sess.run([variable_names,trainables])\n",
    "    for k, v in zip(variable_names,values):\n",
    "        print([\"variable: \" , k])\n",
    "        #print([\"value: \" , v])\n",
    "        print([\"variable: \" , np.unicode_.find(k,'output')]) \n",
    "        print([\"shape: \" , v.shape])\n",
    "        #print(v) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
