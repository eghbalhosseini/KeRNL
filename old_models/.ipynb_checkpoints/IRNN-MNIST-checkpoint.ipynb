{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import hashlib\n",
    "import numbers\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.layers import base as base_layer\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import partitioned_variables\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import variables as tf_variables\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell import _Linear\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# uplading mnist data \n",
    "\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 1718\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.002\n",
    "training_steps = 5000\n",
    "batch_size = 32\n",
    "display_step = 250\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "print(\"Total number of batches:\", total_batch)\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 * 28 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "test_len=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x):    \n",
    "    irnn = tf.contrib.rnn.BasicRNNCell(num_units=num_hidden,activation=tf.nn.relu)\n",
    "    output_layer = tf.layers.Dense(num_classes,\n",
    "                                   activation=None,\n",
    "                                   kernel_initializer=tf.orthogonal_initializer(),\n",
    "                                   trainable=True)\n",
    "    # get irnn output \n",
    "    activations, _ = tf.nn.dynamic_rnn(cell=irnn,dtype=tf.float32,inputs=x)\n",
    "    # do batch normalization \n",
    "    batch_normalized=tf.layers.batch_normalization(activations[:, -1, :])\n",
    "    # propagate to output layer  \n",
    "    class_prediction=output_layer(batch_normalized)\n",
    "\n",
    "    return class_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    X=tf.placeholder(\"float\",[None,timesteps,num_input])\n",
    "    Y=tf.placeholder(\"float\",[None,num_classes])\n",
    "    # network output\n",
    "    logits=RNN(X)\n",
    "    # predictions \n",
    "    prediction=tf.nn.softmax(logits)\n",
    "    # define loss \n",
    "    loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y))\n",
    "    # optimization loop \n",
    "    with tf.variable_scope('optimizer'):\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.1)\n",
    "        # get gradient for gradient clipping \n",
    "        gradients=optimizer.compute_gradients(loss_op)\n",
    "        # clipping operation\n",
    "        # apply gradients \n",
    "        train_op=optimizer.apply_gradients(gradients)\n",
    "        \n",
    "    with tf.variable_scope('evaluate'):\n",
    "        correct_predictions=tf.equal(tf.argmax(prediction,1),tf.argmax(Y,1))\n",
    "        accuracy= tf.reduce_mean(tf.cast(correct_predictions,tf.float32))\n",
    "    \n",
    "    # initialize variables \n",
    "    init=tf.global_variables_initializer()\n",
    "    saver=tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2.3000, Training Accuracy= 0.156, Test Accuracy= 0.078\n",
      "Step 250, Minibatch Loss= 2.3135, Training Accuracy= 0.031, Test Accuracy= 0.078\n"
     ]
    }
   ],
   "source": [
    "# configure training and saving \n",
    "log_dir = \"logs/irnn/%s\" % datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "Path(log_dir).mkdir(exist_ok=True, parents=True)\n",
    "tb_writer = tf.summary.FileWriter(log_dir, graph)\n",
    "# run a training session \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1,training_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x=batch_x.reshape((batch_size,timesteps,num_input))\n",
    "        # run optimizaer \n",
    "        sess.run(train_op,feed_dict={X:batch_x, Y:batch_y})\n",
    "        # show interim performance \n",
    "        if step % display_step==0 or step==1 : \n",
    "            # get batch loss and accuracy \n",
    "            loss, acc= sess.run([loss_op,accuracy],feed_dict={X:batch_x, Y:batch_y})\n",
    "            # write summary \n",
    "            #tb_writer.add_summary(acc,global_step=step)\n",
    "            #tb_writer.flush()\n",
    "            # evaluate performance on test data \n",
    "            test_X=mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "            test_Y=mnist.test.labels[:test_len]\n",
    "            test_acc=sess.run(accuracy,feed_dict={X:test_X, Y:test_Y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc) + \", Test Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(test_acc))\n",
    "         \n",
    "    print(\"Optimization Finished!\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(KeRNL)",
   "language": "python",
   "name": "kernl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
