{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customRNNcell(tf.contrib.rnn.RNNCell):\n",
    "    def __init__(self, input_dim):\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.W = tf.get_variable(\"W\", [self.input_dim , 1], tf.float32)\n",
    "        self.b = tf.get_variable(\"b\", [1])\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return 1\n",
    "\n",
    "    def __call__(self, inputs, state):\n",
    "        output =state*tf.nn.sigmoid(tf.matmul(inputs, self.W)+ self.b)\n",
    "\n",
    "        return output, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapRnnModel(input_tensor, initial_tensor):\n",
    "\n",
    "    cap_cell = customRNNcell(input_dim=5)\n",
    "    cap_series, final_cap = tf.nn.dynamic_rnn(cell=cap_cell, inputs=input_tensor, initial_state=initial_tensor)\n",
    "\n",
    "    return  cap_series , final_cap\n",
    "\n",
    "x_place=tf.placeholder(tf.float32 , [1,2,3,4,5])\n",
    "init_cap_place=tf.placeholder(tf.float32 , [1,1])\n",
    "\n",
    "y=CapRnnModel(x_place, init_cap_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    a=np.random.rand(1,2,3)\n",
    "    b=np.random.rand(1,1)\n",
    "    result=sess.run(y,feed_dict={x_place:a , init_cap_place:b})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = tf.nn.rnn_cell.BasicRNNCell(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell.weights\n",
    "init_state=rnn_cell.zero_state(12,dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "                 [[3, 3, 3], [4, 4, 4]],\n",
    "                 [[5, 5, 5], [6, 6, 6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29, shape=(1, 1, 3), dtype=int32, numpy=array([[[3, 3, 3]]], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(t, [1, 0, 0], [1, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=tf.constant(tf.transpose([1,2,3,4,5,6,7,8,9]),shape=[9,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=128, shape=(3, 1), dtype=int32, numpy=\n",
       "array([[7],\n",
       "       [8],\n",
       "       [9]], dtype=int32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2=tf.slice(t1,[6,0],[3,1])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=153, shape=(12, 1), dtype=int32, numpy=\n",
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]], dtype=int32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([t1,t2],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=71, shape=(2, 1), dtype=int32, numpy=\n",
       "array([[3],\n",
       "       [6]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(t2,[0,2],[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = [[1], [2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = [[4], [5], [6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [9,1] vs. shape[1] = [3,1] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5d197dc9c999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KeRNL/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1112\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1113\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KeRNL/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KeRNL/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [9,1] vs. shape[1] = [3,1] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "tf.concat([t1,t2],1)\n",
    "t(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "\n",
    "class CapRNNcell(tf.contrib.rnn.RNNCell):\n",
    "    def __init__(self, input_dim):\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.W = tf.get_variable(\"W\", [self.input_dim , 1], tf.float32)\n",
    "        self.b = tf.get_variable(\"b\", [1])\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return 1\n",
    "\n",
    "    def __call__(self, inputs, state):\n",
    "        output =state*tf.nn.sigmoid(tf.matmul(inputs, self.W)+ self.b)\n",
    "\n",
    "        return output, output\n",
    "\n",
    "def CapRnnModel(timeSeries_before_forgetting_gate, init_cap):\n",
    "\n",
    "    cap_cell = CapRNNcell(input_dim=3)\n",
    "    cap_series, final_cap = tf.nn.dynamic_rnn(cell=cap_cell, inputs=timeSeries_before_forgetting_gate, initial_state=init_cap)\n",
    "\n",
    "    return  cap_series , final_cap\n",
    "\n",
    "x_place=tf.placeholder(tf.float32 , [1,2,3])\n",
    "init_cap_place=tf.placeholder(tf.float32 , [1,1])\n",
    "\n",
    "y=CapRnnModel(x_place, init_cap_place)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    a=np.random.rand(1,2,3)\n",
    "    b=np.random.rand(1,1)\n",
    "    result=sess.run(y,feed_dict={x_place:a , init_cap_place:b})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps=1000\n",
    "num_input=1\n",
    "batch_size=1\n",
    "batch_x=spike_rec=tf.where(tf.greater(tf.random_uniform(shape=[batch_size,num_input,timesteps]),0.5),\n",
    "                  tf.constant(1.0,shape=[batch_size,num_input,timesteps],dtype=tf.float32),\n",
    "                              tf.constant(0.0,shape=[batch_size,num_input,timesteps],dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=171, shape=(1, 1, 1000), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "         0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "         1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "         0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "         1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "         0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "         1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "         0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "         1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "         1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "         0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "         0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "         0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "         1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "         0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "         0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "         0., 1., 0., 0., 1., 1., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
